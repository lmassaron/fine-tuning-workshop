{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmassaron/fine-tuning-workshop/blob/main/01_knowledge_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the output of the **NVIDIA System Management Interface (nvidia-smi)**, a command-line utility used for monitoring and managing NVIDIA GPU devices. It provides a real-time snapshot of the GPU's status and the processes utilizing it.\n",
        "\n",
        "Here's a breakdown of what each section of the output means:\n",
        "\n",
        "### Header Information\n",
        "\n",
        "The top section provides details about the installed NVIDIA driver and the CUDA version it supports.\n",
        "\n",
        "| Header | Value | Description |\n",
        "|---|---|---|\n",
        "| `NVIDIA-SMI` | `550.163.01` | The version of the nvidia-smi utility itself. |\n",
        "| `Driver Version` | `550.163.01` | The version of the installed NVIDIA display driver. |\n",
        "| `CUDA Version` | `12.4` | The highest version of CUDA that is supported by the installed driver. |\n",
        "\n",
        "### GPU Details Table\n",
        "\n",
        "This table provides detailed information about the GPU installed in the system.\n",
        "\n",
        "| Metric | Value | Description |\n",
        "|---|---|---|\n",
        "| `GPU` | `0` | The index of the GPU in the system. Since it's 0, this is the first and only GPU. |\n",
        "| `Name` | `NVIDIA GeForce RTX 3090` | The model of the graphics card. |\n",
        "| `Persistence-M` | `Off` | Persistence mode. When \"On\", the NVIDIA driver remains loaded even when no applications are using the GPU. |\n",
        "| `Bus-Id` | `00000000:01:00.0` | The PCI bus address of the GPU, which helps in identifying the physical slot it's in. |\n",
        "| `Disp.A` | `On` | Display Active. This indicates whether a display is connected to and active on this GPU. |\n",
        "| `Volatile Uncorr. ECC` | `N/A` | Information about volatile uncorrectable ECC (Error Correction Code) memory errors. \"N/A\" means it's not applicable to this GPU. |\n",
        "| `Fan` | `30%` | The current speed of the GPU's cooling fan as a percentage of its maximum speed. |\n",
        "| `Temp` | `36C` | The current temperature of the GPU in degrees Celsius. |\n",
        "| `Perf` | `P5` | The current performance state of the GPU. This ranges from P0 (maximum performance) to P12 (minimum performance). |\n",
        "| `Pwr:Usage/Cap` | `33W / 350W` | The current power consumption of the GPU in watts compared to its maximum power capacity. |\n",
        "| `Memory-Usage` | `382MiB / 24576MiB` | The amount of dedicated GPU memory currently in use out of the total available memory. |\n",
        "| `GPU-Util` | `36%` | The percentage of time the GPU's processing cores were active over a specific period. |\n",
        "| `Compute M.` | `Default` | The compute mode of the GPU. \"Default\" allows multiple processes to use the GPU for compute tasks simultaneously. |\n",
        "\n",
        "### Processes Table\n",
        "\n",
        "This section lists the processes that are currently using the GPU's resources.\n",
        "\n",
        "| Column | Description |\n",
        "|---|---|\n",
        "| `GPU` | The index of the GPU being used by the process. |\n",
        "| `GI` & `CI` | Graphics and Compute Instance IDs. These are used for Multi-Instance GPU (MIG) functionality, which is not active here (\"N/A\"). |\n",
        "| `PID` | The Process ID of the application using the GPU. |\n",
        "| `Type` | The type of context the process is using: \"G\" for Graphics, \"C\" for Compute, and \"C+G\" for both. In this case, all listed processes are using the GPU for graphics. |\n",
        "| `Process name` | The name of the process. Here we see the X.Org display server, the GNOME desktop environment's shell, and the Visual Studio Code editor. |\n",
        "| `GPU Memory Usage` | The amount of the GPU's memory being used by that specific process. |"
      ],
      "metadata": {
        "id": "nx1LnM8qdXSu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhNrI5idd_vH",
        "outputId": "9be9d09c-7036-4850-bcba-ecab49a09e80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep 25 07:35:12 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check the GPU information\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`%%capture` is a \"magic command\" in IPython, which is the interactive shell that powers Jupyter notebooks. Magic commands are special commands that are not part of the Python language itself but provide extra functionality within the IPython/Jupyter environment.\n",
        "\n",
        "Specifically, `%%capture` is a **cell magic**, which means it starts with `%%` and applies to the entire code cell in which it is placed. Its primary purpose is to **prevent the output of a code cell from being displayed and to capture that output into a variable**.\n",
        "\n",
        "### Basic Usage\n",
        "\n",
        "The most basic way to use `%%capture` is to simply put it at the top of a cell. This will run the code in the cell but will discard all the output.\n",
        "\n",
        "```python\n",
        "%%capture\n",
        "print(\"This output will be hidden.\")\n",
        "```\n",
        "\n",
        "### Storing Captured Output\n",
        "\n",
        "To make `%%capture` truly useful, you can provide a variable name after it. The captured output will be stored in an object in that variable.\n",
        "\n",
        "```python\n",
        "%%capture my_output\n",
        "import sys\n",
        "\n",
        "print(\"This is standard output.\")\n",
        "print(\"This is an error message.\", file=sys.stderr)\n",
        "```\n",
        "\n",
        "After running this cell, the variable `my_output` will contain a special `CapturedIO` object. You can then access the captured output through its attributes:\n",
        "\n",
        "*   `my_output.stdout`: A string containing everything that was sent to standard output.\n",
        "*   `my_output.stderr`: A string containing everything that was sent to standard error.\n",
        "\n",
        "You can then print these variables to see the captured content:\n",
        "\n",
        "```python\n",
        "print(\"--- Standard Output ---\")\n",
        "print(my_output.stdout)\n",
        "print(\"--- Standard Error ---\")\n",
        "print(my_output.stderr)\n",
        "```"
      ],
      "metadata": {
        "id": "V93pX8f8dq6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a brief description of each package:\n",
        "\n",
        "*   **`transformers`**: Developed by Hugging Face, this is a foundational library providing a vast collection of pre-trained models (like BERT, GPT, and Llama) for a wide range of tasks in natural language processing, computer vision, and audio. It simplifies downloading and using these state-of-the-art models with a consistent API.\n",
        "\n",
        "*   **`trl`**: Standing for Transformer Reinforcement Learning, `trl` is a library designed to fine-tune models from the `transformers` library using reinforcement learning techniques. It simplifies advanced training methods like Supervised Fine-Tuning (SFT) and Proximal Policy Optimization (PPO).\n",
        "\n",
        "*   **`accelerate`**: Also from Hugging Face, `accelerate` is a library that simplifies running PyTorch training scripts across different types of hardware (like multiple GPUs or TPUs) with minimal code changes. It handles the boilerplate code for distributed training and mixed-precision, making it easier to scale up your model training.\n",
        "\n",
        "*   **`bitsandbytes`**: This is a lightweight library that provides powerful quantization methods, allowing you to run and train large language models with significantly less memory. Its key features are 8-bit and 4-bit quantization, which dramatically reduce the GPU memory footprint of a model, making it possible to work with very large models on consumer-grade hardware."
      ],
      "metadata": {
        "id": "TFRCCwgveLmw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XnjgsKN_esrw"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries for model training and evaluation\n",
        "%%capture\n",
        "!pip install -U transformers trl accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbszOixGedSt",
        "outputId": "af2bac13-ead0-4cd1-8c4e-8468138c6664"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using PyTorch version: 2.8.0+cu126\n",
            "Using TRL version: 0.23.0\n",
            "Using bitsandbytes version: 0.47.0\n"
          ]
        }
      ],
      "source": [
        "# Import and print the versions of the installed libraries\n",
        "import torch\n",
        "import trl\n",
        "import bitsandbytes\n",
        "\n",
        "print(f\"Using PyTorch version: {torch.__version__}\")\n",
        "print(f\"Using TRL version: {trl.__version__}\")\n",
        "print(f\"Using bitsandbytes version: {bitsandbytes.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YfeOmO0cfNGh"
      },
      "outputs": [],
      "source": [
        "# Import various libraries needed for data handling, model loading, and training\n",
        "import os\n",
        "import gc\n",
        "import warnings\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from datasets import Dataset, load_dataset\n",
        "from huggingface_hub import login\n",
        "from peft import LoraConfig\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from trl import SFTConfig, SFTTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This class acts as a **centralized place to store and manage important settings** for a machine learning script, specifically for running Google's Gemma model.\n",
        "\n",
        "The reasons for using it are:\n",
        "\n",
        "*   **Easy to Change:** You can quickly change the model size (e.g., from `\"3-1b\"` to `\"7b\"`) or token lengths in one spot without hunting through the code.\n",
        "*   **Keeps Code Clean:** It groups all the key parameters together, making the main script more readable and organized.\n",
        "*   **Avoids \"Magic Numbers\":** It gives descriptive names (`max_prompt_length`) to numbers that would otherwise be scattered throughout the code, making their purpose clear."
      ],
      "metadata": {
        "id": "HeqSZp5Gflvx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CrTseGUkffTN"
      },
      "outputs": [],
      "source": [
        "# Define configuration parameters for the model and data\n",
        "class Config:\n",
        "    \"\"\"Configuration parameters\"\"\"\n",
        "\n",
        "    SIZE = \"3-1b\"\n",
        "    MODEL_NAME = f\"google/gemma-{SIZE}-it\"\n",
        "\n",
        "    max_prompt_length = 352\n",
        "    max_completion_length = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Gemma 3 Instruct\" model family.\n",
        "\n",
        "### Gemma 3 4B-Instruct: The Efficient Workhorse\n",
        "\n",
        "This model would be the balanced, general-purpose choice, offering a strong blend of performance and efficiency. It's designed to be a capable and reliable assistant for a wide range of tasks without requiring high-end, specialized hardware.\n",
        "\n",
        "*   **Reasoning:** Good to Strong\n",
        "*   **Speed:** Fast\n",
        "*   **Hardware:** Consumer GPUs, Cloud CPUs\n",
        "*   **Ideal Use Cases:**\n",
        "    *   General-purpose chatbots\n",
        "    *   RAG & summarization\n",
        "    *   Developer co-pilots\n",
        "    *   Content creation\n",
        "\n",
        "**Key Strengths:**\n",
        "*   **Excellent Performance-to-Size Ratio:** Its primary strength is delivering high-quality, nuanced responses that are competitive with larger models, while being significantly faster and less resource-intensive.\n",
        "*   **Strong General Reasoning:** It would be capable of handling moderately complex tasks like multi-turn conversations, detailed content summarization, and Retrieval-Augmented Generation (RAG).\n",
        "*   **High Accessibility:** Small enough to run efficiently on consumer-grade GPUs, making it a go-to choice for developers, researchers, and small businesses.\n",
        "*   **Reliable Instruction Following:** As an instruct-tuned model, it would excel at following complex prompts and adhering to specific formats, making it ideal for creating dependable chatbots and assistants.\n",
        "\n",
        "---\n",
        "\n",
        "### Gemma 3 1B-Instruct: The Ultra-Lightweight Specialist\n",
        "\n",
        "This model prioritizes speed and extreme efficiency above all else. It's designed for applications where low latency and a minimal resource footprint are critical, such as on-device or real-time tasks.\n",
        "\n",
        "*   **Reasoning:** Basic to Moderate\n",
        "*   **Speed:** Blazing Fast\n",
        "*   **Hardware:** Standard CPUs, Mobile Devices\n",
        "*   **Ideal Use Cases:**\n",
        "    *   Real-time text classification\n",
        "    *   Simple, high-volume tasks\n",
        "    *   On-device voice commands\n",
        "    *   Basic customer service bots\n",
        "\n",
        "**Key Strengths:**\n",
        "*   **Blazing Speed and Low Latency:** It would provide near-instantaneous responses, which is crucial for interactive applications, simple chatbots, and processing high volumes of text quickly.\n",
        "*   **On-Device Deployment:** Its small size makes it perfect for running directly on mobile phones, laptops, and edge devices, enabling AI applications that work offline and with enhanced privacy.\n",
        "*   **Cost-Effectiveness at Scale:** Extremely cheap to run, making it the best option for high-volume, simple tasks like text classification, sentiment analysis, or command parsing.\n",
        "*   **Excellent for Fine-Tuning:** Small models are fast and inexpensive to fine-tune, allowing developers to easily create a highly specialized expert for a single, narrow task.\n",
        "\n",
        "---\n",
        "\n",
        "### Gemma 3 270M-Instruct: The Specialized Micro-Model\n",
        "\n",
        "This is an extremely compact model. It is not designed for general conversation or complex reasoning. Instead, its strength lies in being a highly efficient foundation for a single, well-defined task, often after being fine-tuned.\n",
        "\n",
        "*   **Reasoning:** Very Limited (before fine-tuning)\n",
        "*   **Speed:** Near-Instantaneous\n",
        "*   **Hardware:** Microcontrollers, In-Browser\n",
        "*   **Ideal Use Cases:**\n",
        "    *   Fine-tuned classifiers (e.g., toxicity)\n",
        "    *   Smart text filters (e.g., PII detection)\n",
        "    *   Format checking (e.g., JSON)\n",
        "    *   Low-power/edge devices\n",
        "    \n",
        "**Key Strengths:**\n",
        "*   **Minimal Resource Footprint:** The smallest and most efficient option, capable of running on virtually any hardware, including microcontrollers and in-browser environments (WebAssembly).\n",
        "*   **Task-Specific Excellence:** While poor at general tasks, it can become exceptionally good at one specific thing after fine-tuning. For example, it could be trained to be a world-class toxicity detector, a PII (Personally Identifiable Information) scrubber, or a format checker.\n",
        "*   **Energy Efficiency:** Its low computational requirements make it ideal for battery-powered and low-power devices where energy consumption is a major concern.\n",
        "*   **Simple Integration:** Can be easily integrated into larger systems as a fast, intelligent filter or classifier."
      ],
      "metadata": {
        "id": "XPNiF2iIs-o0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`init()`\n",
        "\n",
        "This function **sets up the entire environment** for the script to run properly. It does three main things:\n",
        "1.  **Configures Settings:** It sets several environment variables to ensure stability, control which GPU is used (`\"0\"`), and manage memory allocation.\n",
        "2.  **Handles Login:** It automatically logs into Hugging Face by looking for your access token, first in the standard environment variables and then specifically in Google Colab's secure \"secrets\" manager.\n",
        "3.  **Cleans Up:** It frees up GPU memory, runs Python's garbage collector to free up system RAM, and silences warning messages for a cleaner output.\n",
        "\n",
        "`is_bfloat16_supported()`\n",
        "\n",
        "This function is a **hardware check**. It checks if the available NVIDIA GPU has the necessary architecture (Compute Capability 8.0 or higher, like an A100 or RTX 30/40 series) to support the `bfloat16` data type, which is an efficient format for training modern deep learning models. It returns `True` if it's supported and `False` if it's not.\n",
        "\n",
        "`info_device()`\n",
        "\n",
        "This function **determines the best hardware to use** for computations. It checks if a CUDA-enabled GPU is available and selects it. If not, it falls back to using the CPU. It then prints a message to inform you which device is being used (`\"cuda\"` or `\"cpu\"`) and returns this device object so the rest of the program knows where to send the model and data."
      ],
      "metadata": {
        "id": "LxbubbXVf5Z_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0_hM-990eqrr"
      },
      "outputs": [],
      "source": [
        "# Initialization script to set up the environment and Hugging Face login\n",
        "def init():\n",
        "    \"\"\"Initialization script\"\"\"\n",
        "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "    # It is recommended to set the HF_TOKEN as an environment variable\n",
        "    token = os.environ.get(\"HF_TOKEN\")\n",
        "    if token:\n",
        "        login(token=token)\n",
        "    else:\n",
        "      try:\n",
        "        from google.colab import userdata\n",
        "        # Retrieve your Hugging Face token from Colab's secrets manager\n",
        "        # The name 'HF_TOKEN' should match the name you used in the secrets tab\n",
        "        hf_token = userdata.get('HF_TOKEN')\n",
        "\n",
        "        # Check if the token was successfully retrieved\n",
        "        if hf_token:\n",
        "            # Log in to Hugging Face using the retrieved token\n",
        "            # The `add_to_git_credential=True` argument is optional and useful if you plan to push models to the Hub\n",
        "            login(token=hf_token, add_to_git_credential=True)\n",
        "            print(\"Hugging Face login successful using Google Colab secrets!\")\n",
        "        else:\n",
        "            print(\"Error: HF_TOKEN not found in Google Colab secrets or is empty.\")\n",
        "            print(\"Please ensure you have created a secret named 'HF_TOKEN' in the 'Secrets' tab (ðŸ”‘) on the left sidebar.\")\n",
        "      except:\n",
        "        print(\"HF_TOKEN not set. You might need to log in manually.\")\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def is_bfloat16_supported():\n",
        "    \"\"\"Checks if the current device supports bfloat16.\"\"\"\n",
        "    return torch.cuda.is_available() and torch.cuda.get_device_capability(0)[0] >= 8\n",
        "\n",
        "\n",
        "def info_device():\n",
        "    \"\"\"Get device for PyTorch\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "    return device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lW6ft5_SfOV5",
        "outputId": "9f760642-6fed-47e8-8ebf-375b32fafb08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hugging Face login successful using Google Colab secrets!\n",
            "Using device: cuda\n",
            "Using dtype: torch.float16\n"
          ]
        }
      ],
      "source": [
        "# Initialize the environment, get parameters, device, and data type\n",
        "init()\n",
        "params = Config()\n",
        "device = info_device()\n",
        "dtype = torch.bfloat16 if is_bfloat16_supported() else torch.float16\n",
        "print(f\"Using dtype: {dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1OtC1THhf0VS"
      },
      "outputs": [],
      "source": [
        "# Function to load dataset from Hugging Face Hub\n",
        "def get_data(repo_id, mapping_func=None, split=\"train\"):\n",
        "    \"\"\"Upload HF dataset\"\"\"\n",
        "    data = load_dataset(repo_id, cache_dir=\"/tmp\")[split]\n",
        "    if mapping_func:\n",
        "      data = data.map(mapping_func)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The line `get_data(repo_id=\"lmassaron/Sherlock_QA_test\")` does the following:\n",
        "\n",
        "1.  **Downloads a Dataset:** It connects to the Hugging Face Hub and downloads the dataset named `Sherlock_QA_test`. This is an example of expert-based QA for testing purposes.\n",
        "2.  **Selects the Training Data:** By default, it selects the `\"train\"` split from that dataset.\n",
        "3.  **Returns the Data:** It returns this training data and stores it in the `data` variable without applying any transformations (since no `mapping_func` was provided)."
      ],
      "metadata": {
        "id": "w4H7v40PggXE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ty8thGnhB1M"
      },
      "outputs": [],
      "source": [
        "# Load the Sherlock QA dataset\n",
        "data = get_data(repo_id=\"lmassaron/Sherlock_QA_test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Hugging Face `Dataset` object structures data like a **highly efficient, memory-mapped table** (similar to a spreadsheet or a database table).\n",
        "\n",
        "In regard of our dataset:\n",
        "\n",
        "*   `features: ['Question', 'Answer', 'Difficulty']`: These are the **columns** of the table. Every single entry in the dataset will have these three fields.\n",
        "\n",
        "*   `num_rows: 25`: This is the total number of **rows** or records in the table.\n",
        "\n",
        "So, you can think of this dataset as a table with **25 rows** and **3 columns**: `Question`, `Answer`, and `Difficulty`.\n",
        "\n",
        "The key difference from a simple list of dictionaries is that the `datasets` library uses **Apache Arrow** on the backend. This allows it to handle massive datasets that don't fit in RAM by only loading the data from your disk as you need it, making it extremely fast and memory-efficient."
      ],
      "metadata": {
        "id": "2kZlEECJg5TZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19ihvnylhGEE",
        "outputId": "d3d131a7-29f6-42da-ed9f-4506249048b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Question', 'Answer', 'Difficulty'],\n",
              "    num_rows: 25\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Display the loaded dataset information\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, question in enumerate(data[\"Question\"]):\n",
        "  print(f\"{i:2}. {question}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AsdyrUJ3EtW",
        "outputId": "eb5941a8-1380-4402-e563-ceb42467510a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0. Who created the character of Sherlock Holmes?\n",
            " 1. What is the name of Sherlock Holmes's enemy?\n",
            " 2. Where does Sherlock Holmes live?\n",
            " 3. Who is Sherlock Holmes's best friend?\n",
            " 4. What is the name of Sherlock's older brother?\n",
            " 5. Who is the landlady of 221b Baker Street?\n",
            " 6. What musical instrument does Sherlock Holmes like to play?\n",
            " 7. In which Sherlock Holmes short story do we meet Irene Adler?\n",
            " 8. Which actor plays Sherlock Holmes in the TV series Sherlock?\n",
            " 9. Who did Dr. Watson marry?\n",
            "10. What are the street boys called who run errands for Sherlock Holmes?\n",
            "11. Who stars as Sherlock Holmes in the 2009 film Sherlock Holmes?\n",
            "12. Who stars as Watson in the 2009 film Sherlock Holmes?\n",
            "13. What was the first Sherlock Holmes story titled?\n",
            "14. Which 2020 film features the teenage sister of Sherlock Holmes?\n",
            "15. Where did Sherlock and Watson first meet?\n",
            "16. When Sherlock Holmes retired, what hobby did he take up?\n",
            "17. Where does Sherlock Holmes keep his tobacco?\n",
            "18. What is the client's name in the short story \"The Five Orange Pips\"?\n",
            "19. What was the title of the short story published in 1893, intended to be the final Sherlock story?\n",
            "20. What was the first book released after everyone believed Sherlock Holmes to be dead?\n",
            "21. What object is the Blue Carbuncle?\n",
            "22. What is Sherlock Holmes's most famous line?\n",
            "23. On what British TV channel is the series Sherlock shown?\n",
            "24. In The Hound Of The Baskervilles, what village does Dr. James Mortimer live in?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`AutoTokenizer` is a smart class from the Hugging Face `transformers` library. Its job is to **download the correct tokenizer for any given pre-trained model.**\n",
        "\n",
        "Think of a tokenizer as a model-specific dictionary. It converts your text into a sequence of numbers (tokens) that the model can understand and converts the model's numerical output back into human-readable text. The \"Auto\" part is the key: you just give it a model name (like `\"google/gemma-3-1b-it\"`), and it automatically figures out the right tokenizer to use, saving you from having to find the specific class yourself."
      ],
      "metadata": {
        "id": "mYz14PdLhoL5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`AutoModelForCausalLM` is another smart class from Hugging Face that **downloads the pre-trained weights and architecture for a model designed for causal language modeling.**\n",
        "\n",
        "\"Causal Language Modeling\" is the task of predicting the next token in a sequence of text. This is the fundamental task for generative models like GPT and Gemma. Just like `AutoTokenizer`, the \"Auto\" part automatically selects the correct model architecture based on the name you provide.\n",
        "\n",
        "#### Parameters:\n",
        "\n",
        "*   `params.MODEL_NAME`: The identifier of the model on the Hugging Face Hub (e.g., `\"google/gemma-3-1b-it\"`). This tells the function *what* model to load.\n",
        "*   `torch_dtype=dtype`: This sets the numerical precision (e.g., `float16` or `bfloat16`) for the model's weights. Using a lower precision than the default (`float32`) significantly **reduces the model's memory footprint and speeds up computation**, which is crucial for running large models.\n",
        "*   `device_map=device`: This tells the library **where to place the model's layers** (e.g., on the GPU, specified by `device=\"cuda\"`). For very large models, this can even be used to automatically distribute layers across multiple GPUs.\n",
        "*   `use_cache=True`: This enables a key-value cache during text generation. This is a significant optimization that **dramatically speeds up the process of generating long sequences of text** by reusing previous calculations instead of recomputing them for every new word."
      ],
      "metadata": {
        "id": "Qp-YMxuBhoEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You set the `tokenizer.pad_token` to handle **batch processing**.\n",
        "\n",
        "When you send a batch of multiple sentences to the model, they all must have the same length. To achieve this, shorter sentences are \"padded\" by adding a special token to them until they match the length of the longest sentence in the batch.\n",
        "\n",
        "However, some models, especially those designed purely for text generation (like Gemma), are not trained with a specific padding token. In this case, `tokenizer.pad_token` is `None`. By setting `tokenizer.pad_token = tokenizer.eos_token` (the \"end-of-sequence\" token), we are telling the tokenizer to **use the end-of-sequence token for padding**. This is a common and safe practice because the model is already trained to understand that the `eos_token` signifies the end of meaningful content and will effectively ignore it during processing."
      ],
      "metadata": {
        "id": "G1IyTB-bhn3q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ag2jIkzshLAK"
      },
      "outputs": [],
      "source": [
        "# Load the tokenizer and model from Hugging Face\n",
        "tokenizer = AutoTokenizer.from_pretrained(params.MODEL_NAME)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    params.MODEL_NAME,\n",
        "    torch_dtype=dtype,\n",
        "    device_map=device,\n",
        "    use_cache=True\n",
        ")\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Two Different Processes\n",
        "\n",
        "1.  **Text Generation (`model.generate`)**: This is an **autoregressive process**. The model predicts one token at a time, appends it to the input, and then predicts the next token in a loop. It's a creative, step-by-step procedure designed to *produce new text*. It often involves sampling strategies (like temperature) and uses an internal cache to be efficient. You are asking the model: **\"What comes next?\"** over and over again.\n",
        "\n",
        "2.  **Perplexity Calculation (`model(...)`)**: This is a **single forward pass** on a *complete, existing sequence of text*. You provide the entire sequence to the model at once and ask it to calculate the probability of that sequence. This is done by measuring the cross-entropy loss between the model's predictions and the actual tokens in the sequence. You are asking the model: **\"How probable or 'fluent' was this entire sequence?\"**\n",
        "\n",
        "### What Does This Perplexity Score Actually Measure?\n",
        "\n",
        "We are calculating the perplexity of the **model's own generated answer**.\n",
        "\n",
        "*   **This is a measure of the model's internal confidence or fluency.**\n",
        "    *   A **low perplexity** score means the model generated a sequence of tokens that it found highly probable and predictable. The answer is \"fluent\" according to its own internal patterns (e.g., \"The sky is blue.\").\n",
        "    *   A **high perplexity** score means the model generated a sequence that it found surprising or unlikely. This could indicate a less confident answer, a more complex or unusual phrasing, or potential disfluency.\n",
        "\n",
        "**This is different from another common use of perplexity**, where you would measure the perplexity of the `expected_answer` (the ground truth). That would tell you how well the model might have predicted the \"correct\" answer, whereas your current code tells you how confident the model was in its *own* answer. Both are valid and useful metrics, but they measure different things.\n"
      ],
      "metadata": {
        "id": "4aT5w3JQvlu_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`inputs = tokenizer.apply_chat_template(...)`\n",
        "\n",
        "This section **formats the user's question into the specific conversational structure that the chat model was trained on.** It takes a simple question and wraps it with special tokens and role identifiers (like `user` and `model`) to create a formal prompt. It then tokenizes this formatted prompt, converts it into a PyTorch tensor, and moves it to the correct device (e.g., the GPU) to be ready for the model.\n",
        "\n",
        "`outputs = model.generate(...)`\n",
        "\n",
        "This is the **core text generation step.** It feeds the prepared `inputs` into the model and instructs it to predict the next sequence of tokens. The `attention_mask` is crucial here, as it tells the model which tokens are real and which are just padding, ensuring it doesn't get confused by the padding added for batching. The `**generation_kwargs` would contain other settings that control the generation process, like the maximum length or the sampling strategy.\n",
        "\n",
        "`generated_text = tokenizer.decode(...)`\n",
        "\n",
        "This final section **translates the model's numerical output back into human-readable text.** It first slices the output tensor to isolate only the newly generated tokens (stripping away the original input prompt). It then uses the tokenizer's `decode` method to convert these token IDs back into words, while also removing any special tokens (like the end-of-sequence token) for a clean, final answer."
      ],
      "metadata": {
        "id": "OupR2iiPioeH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`generated_token_ids = outputs[0, inputs.input_ids.shape[-1] :]` is for **separating the model's newly generated answer from the original prompt you gave it.**\n",
        "\n",
        "Here's the breakdown:\n",
        "\n",
        "1.  **`outputs`**: The `model.generate` function returns the **entire sequence of tokens**, which includes your original input prompt *plus* the model's generated response appended at the end.\n",
        "\n",
        "2.  **`inputs.input_ids.shape[-1]`**: This gets the **length of your original input prompt** in tokens.\n",
        "\n",
        "3.  **`[0, inputs.input_ids.shape[-1] :]`**: This is a tensor slicing operation.\n",
        "    *   `0`: Selects the first (and likely only) sequence in the batch.\n",
        "    *   `inputs.input_ids.shape[-1] :`: This tells Python to \"start slicing from the index where the input prompt ends, and go all the way to the end of the sequence.\""
      ],
      "metadata": {
        "id": "UyQhjH0li-ES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of course. Let's break down this command with a simple analogy.\n",
        "\n",
        "Think of this command as giving the model a **pop quiz** to see how well it knows the text you just gave it.\n",
        "\n",
        "### High-Level Explanation\n",
        "\n",
        "In one sentence, this command feeds the entire generated sentence back into the model at once and asks it: **\"How well could you have predicted this exact sentence?\"** Because you provide the `labels` (the correct answers), the model automatically calculates a `loss` score that measures how \"surprised\" or wrong its predictions were.\n",
        "\n",
        "---\n",
        "\n",
        "`outputs_perplexity = model( ... )`\n",
        "\n",
        "This is a **forward pass**, the most fundamental operation of a neural network. It's different from `model.generate()`, which is a step-by-step loop.\n",
        "\n",
        "1.  **`generated_inputs.input_ids` (The Quiz Questions)**\n",
        "    *   **What it is:** The sequence of numerical tokens representing the text you want to evaluate (e.g., `[101, 2009, 3209, 2332]`).\n",
        "    *   **Its Role:** This is the input sequence. At each position, the model will try to predict the *next* token.\n",
        "\n",
        "2.  **`generated_inputs.attention_mask` (The \"Focus\" Instructions)**\n",
        "    *   **What it is:** A tensor of 1s and 0s that tells the model which tokens are real and which are just padding.\n",
        "    *   **Its Role:** It ensures the model only pays attention to the actual content and isn't confused by any padding that might be present.\n",
        "\n",
        "3.  **`labels=labels` (The Answer Key)**\n",
        "    *   **What it is:** This is the most important part. It's the sequence of \"correct answers\" that you prepared by shifting the input tokens one step to the left.\n",
        "    *   **Its Role:** By providing the answer key directly to the model, you are activating a special, built-in feature of Hugging Face models.\n"
      ],
      "metadata": {
        "id": "75wJJJ4fxbku"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhzjOp95hXVG",
        "outputId": "dd59b029-9881-4715-f230-fca71c43104e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Samples:   0%|          | 0/25 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:11<00:00,  2.17it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Gemma3ForCausalLM(\n",
              "  (model): Gemma3TextModel(\n",
              "    (embed_tokens): Gemma3TextScaledWordEmbedding(262144, 1152, padding_idx=0)\n",
              "    (layers): ModuleList(\n",
              "      (0-25): 26 x Gemma3DecoderLayer(\n",
              "        (self_attn): Gemma3Attention(\n",
              "          (q_proj): Linear(in_features=1152, out_features=1024, bias=False)\n",
              "          (k_proj): Linear(in_features=1152, out_features=256, bias=False)\n",
              "          (v_proj): Linear(in_features=1152, out_features=256, bias=False)\n",
              "          (o_proj): Linear(in_features=1024, out_features=1152, bias=False)\n",
              "          (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
              "          (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
              "        )\n",
              "        (mlp): Gemma3MLP(\n",
              "          (gate_proj): Linear(in_features=1152, out_features=6912, bias=False)\n",
              "          (up_proj): Linear(in_features=1152, out_features=6912, bias=False)\n",
              "          (down_proj): Linear(in_features=6912, out_features=1152, bias=False)\n",
              "          (act_fn): PytorchGELUTanh()\n",
              "        )\n",
              "        (input_layernorm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
              "        (post_attention_layernorm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
              "        (pre_feedforward_layernorm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
              "        (post_feedforward_layernorm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
              "    (rotary_emb): Gemma3RotaryEmbedding()\n",
              "    (rotary_emb_local): Gemma3RotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1152, out_features=262144, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Evaluate the model on the dataset and store results\n",
        "temperature = 0\n",
        "results_list = []\n",
        "instructions = \"\\nBriefly, just give the straight answer to the question.\"\n",
        "\n",
        "# It's good practice to set the pad_token if it's not already set.\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "for row in tqdm(data, desc=\"Evaluating Samples\"):\n",
        "  question = row['Question']\n",
        "  answer = row['Answer']\n",
        "  difficulty = row['Difficulty']\n",
        "\n",
        "  # Tokenize the input and get both input_ids and attention_mask\n",
        "  inputs = tokenizer.apply_chat_template(\n",
        "            [{\"role\": \"user\", \"content\": question + instructions}],\n",
        "            tokenize=True,\n",
        "            add_generation_prompt=True,  # Crucial for telling the model it's its turn to speak\n",
        "            return_tensors=\"pt\",\n",
        "            return_dict=True  # Ensure the output is a dictionary\n",
        "        ).to(device)\n",
        "\n",
        "  # Prepare arguments for the generate function\n",
        "  generation_kwargs = {\n",
        "      \"pad_token_id\": tokenizer.eos_token_id,\n",
        "      \"max_new_tokens\": params.max_completion_length,\n",
        "      \"do_sample\": temperature > 0\n",
        "  }\n",
        "\n",
        "  # Only add temperature to kwargs if sampling is enabled\n",
        "  if generation_kwargs[\"do_sample\"]:\n",
        "      generation_kwargs[\"temperature\"] = temperature\n",
        "\n",
        "  # Generate a completion from the model, passing the attention_mask\n",
        "  outputs = model.generate(\n",
        "      inputs.input_ids, # Pass input_ids explicitly\n",
        "      attention_mask=inputs.attention_mask, # Pass the attention mask\n",
        "      **generation_kwargs\n",
        "      )\n",
        "\n",
        "  generated_token_ids = outputs[0, inputs.input_ids.shape[-1] :]\n",
        "  generated_text = tokenizer.decode(\n",
        "      generated_token_ids,\n",
        "      skip_special_tokens=True,\n",
        "  ).strip()\n",
        "\n",
        "  # Calculate perplexity for the generated answer\n",
        "  with torch.no_grad():\n",
        "      # Tokenize the generated text\n",
        "      generated_inputs = tokenizer(generated_text, return_tensors=\"pt\").to(device)\n",
        "      # Get the model's logits for the generated text\n",
        "      # We need to handle cases where the generated text is empty\n",
        "      if generated_inputs.input_ids.numel() > 0:\n",
        "          # Ensure labels are shifted for perplexity calculation\n",
        "          labels = generated_inputs.input_ids.clone()\n",
        "          # Shift labels to the left, so that the model predicts the next token\n",
        "          labels[:, :-1] = generated_inputs.input_ids[:, 1:]\n",
        "          # Set the last label to -100 to ignore it in loss calculation\n",
        "          labels[:, -1] = -100\n",
        "\n",
        "          # Get the model's output with attention mask\n",
        "          outputs_perplexity = model(\n",
        "              generated_inputs.input_ids,\n",
        "              attention_mask=generated_inputs.attention_mask,\n",
        "              labels=labels\n",
        "              )\n",
        "          # Calculate the loss\n",
        "          loss = outputs_perplexity.loss\n",
        "          # Calculate perplexity\n",
        "          perplexity = torch.exp(loss).item()\n",
        "      else:\n",
        "          perplexity = float('inf') # Assign infinity for empty generated text\n",
        "\n",
        "\n",
        "  results_list.append({\n",
        "      'question': question,\n",
        "      'expected_answer': answer,\n",
        "      'generated_answer': generated_text,\n",
        "      'difficulty': difficulty,\n",
        "      'perplexity': perplexity # Add perplexity to the results\n",
        "  })\n",
        "\n",
        "results_df = pd.DataFrame(results_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WkXFPkxWRztL"
      },
      "outputs": [],
      "source": [
        "# Delete the model and tokenizer to free up GPU memory\n",
        "del [model, tokenizer]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MypZobdjqjYg"
      },
      "outputs": [],
      "source": [
        "# Evaluate correctness based on keyword matching\n",
        "def evaluate_keyword(row):\n",
        "    return row['expected_answer'].lower() in row['generated_answer'].lower()\n",
        "\n",
        "results_df['is_correct_keyword'] = results_df.apply(evaluate_keyword, axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we ** evaluate if the model's answers are correct by comparing their *semantic meaning*, not just their exact words.**\n",
        "\n",
        "Here's the simple breakdown of the steps:\n",
        "\n",
        "1.  **Convert to Numbers:** It uses a `SentenceTransformer` model to convert both the expected \"correct\" answers and the model's generated answers into numerical vectors (called embeddings). In these vectors, sentences with similar meanings are mathematically close to each other.\n",
        "\n",
        "2.  **Calculate Similarity:** It then calculates the \"cosine similarity\" between the vector for the expected answer and the vector for the generated answer. This results in a score from -1 to 1, where 1 means the meanings are identical.\n",
        "\n",
        "3.  **Make a Decision:** Finally, it checks if this similarity score is above a certain threshold (in this case, `0.5`). If it is, the answer is marked as `True` (correct), even if the wording isn't exactly the same."
      ],
      "metadata": {
        "id": "6haJ39UlkHT9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cosine similarity is a metric used to measure how similar two things are, not by their size or magnitude, but by their **orientation** or **direction**.\n",
        "\n",
        "Imagine two arrows starting from the same point.\n",
        "\n",
        "*   If the arrows point in the **exact same direction**, their cosine similarity is **1** (maximum similarity).\n",
        "*   If the arrows are **perpendicular** (pointing at a 90-degree angle to each other), they are considered unrelated, and their similarity is **0**.\n",
        "*   If they point in **opposite directions**, their similarity is **-1** (maximum dissimilarity).\n",
        "\n",
        "In text analysis, sentences are converted into these \"arrows\" (vectors) in a high-dimensional space. Cosine similarity then tells us if two sentences \"point\" in the same semantic direction, meaning they have a similar topic or meaning, regardless of the exact words used.\n",
        "\n",
        "At its core, the calculation is based on the **dot product** of two vectors divided by the product of their **magnitudes**.\n",
        "\n",
        "Here is the formula:\n",
        "\n",
        "![Cosine Similarity Formula](https://wikimedia.org/api/rest_v1/media/math/render/svg/15d11df2d48da4787ee86a4b8c14551fbf0bc96a)\n",
        "\n",
        "Where:\n",
        "*   **A â‹… B** is the **dot product** of vectors A and B.\n",
        "*   **||A||** and **||B||** are the **magnitudes** (or lengths) of vectors A and B.\n",
        "\n",
        "---\n",
        "\n",
        "### Step-by-Step Calculation with a Simple Example\n",
        "\n",
        "Let's say we want to measure the similarity between two short sentences:\n",
        "*   **Sentence A:** \"the cat sat\"\n",
        "*   **Sentence B:** \"the dog sat\"\n",
        "\n",
        "**Step 1: Convert Sentences to Vectors**\n",
        "\n",
        "First, we create a vocabulary of all unique words: `{\"the\", \"cat\", \"sat\", \"dog\"}`. Then, we count the occurrences of each word in each sentence to create our vectors.\n",
        "\n",
        "*   **Vector A** (for \"the cat sat\"): `[1, 1, 1, 0]`  (1 \"the\", 1 \"cat\", 1 \"sat\", 0 \"dog\")\n",
        "*   **Vector B** (for \"the dog sat\"): `[1, 0, 1, 1]`  (1 \"the\", 0 \"cat\", 1 \"sat\", 1 \"dog\")\n",
        "\n",
        "Now we have our two vectors, `A = [1, 1, 1, 0]` and `B = [1, 0, 1, 1]`.\n",
        "\n",
        "**Step 2: Calculate the Dot Product (A â‹… B)**\n",
        "\n",
        "The dot product is the sum of the products of the corresponding elements in the vectors.\n",
        "\n",
        "`A â‹… B = (1 * 1) + (1 * 0) + (1 * 1) + (0 * 1)`\n",
        "`A â‹… B = 1 + 0 + 1 + 0`\n",
        "`A â‹… B = 2`\n",
        "\n",
        "**Step 3: Calculate the Magnitude of Each Vector (||A|| and ||B||)**\n",
        "\n",
        "The magnitude is the square root of the sum of the squares of all the elements in the vector.\n",
        "\n",
        "*   **Magnitude of A (||A||):**\n",
        "    `||A|| = âˆš(1Â² + 1Â² + 1Â² + 0Â²)`\n",
        "    `||A|| = âˆš(1 + 1 + 1 + 0)`\n",
        "    `||A|| = âˆš3 â‰ˆ 1.732`\n",
        "\n",
        "*   **Magnitude of B (||B||):**\n",
        "    `||B|| = âˆš(1Â² + 0Â² + 1Â² + 1Â²)`\n",
        "    `||B|| = âˆš(1 + 0 + 1 + 1)`\n",
        "    `||B|| = âˆš3 â‰ˆ 1.732`\n",
        "\n",
        "**Step 4: Divide the Dot Product by the Product of the Magnitudes**\n",
        "\n",
        "Now we just plug the results from the previous steps into the main formula.\n",
        "\n",
        "`Cosine Similarity = (A â‹… B) / (||A|| * ||B||)`\n",
        "`Cosine Similarity = 2 / (âˆš3 * âˆš3)`\n",
        "`Cosine Similarity = 2 / 3 â‰ˆ 0.667`\n",
        "\n",
        "The resulting similarity score of **0.667** indicates a strong positive similarity between the two sentences, which makes sense as they share two out of three words."
      ],
      "metadata": {
        "id": "5sZe4a2LkRTm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-b62iLlS1cJb"
      },
      "outputs": [],
      "source": [
        "# Evaluate correctness based on semantic similarity using Sentence-BERT\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Load the Sentence-BERT model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Encode the expected and generated answers into embeddings\n",
        "expected_embeddings = model.encode(results_df['expected_answer'].tolist(), convert_to_tensor=True)\n",
        "generated_embeddings = model.encode(results_df['generated_answer'].tolist(), convert_to_tensor=True)\n",
        "\n",
        "# Calculate cosine similarity between embeddings\n",
        "cosine_scores = util.cos_sim(expected_embeddings, generated_embeddings)\n",
        "cosine_scores = np.array(cosine_scores.cpu())\n",
        "\n",
        "# Store the semantic similarity scores\n",
        "results_df['semantic_similarity'] = [cosine_scores[i][i] for i in range(len(cosine_scores))]\n",
        "\n",
        "# Determine correctness based on a similarity threshold\n",
        "similarity_threshold = 0.5\n",
        "results_df['is_correct_semantic'] = results_df['semantic_similarity'] >= similarity_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EMCEuo_TR352"
      },
      "outputs": [],
      "source": [
        "# Delete the Sentence-BERT model to free up memory\n",
        "del [model]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`meta-llama/Llama-3.2-3B-Instruct`** is a small yet powerful language model from Meta AI, designed to be highly efficient and accessible. The \"3B\" refers to its 3.21 billion parameters, making it lightweight enough to run on consumer hardware and at the edge. The \"-Instruct\" suffix means it has been specifically fine-tuned to follow instructions and engage in dialogue, making it ideal for creating chatbots and assistants.\n",
        "\n",
        "### Key Strengths:\n",
        "\n",
        "*   **Strong Multilingual Capabilities:** The model is explicitly optimized for multilingual use cases and officially supports eight languages: English, German, French, Spanish, Italian, Portuguese, Hindi, and Thai. This is a significant advantage for building global applications.\n",
        "*   **Large Context Window:** It supports a 128,000-token context window, allowing it to understand and process very long documents or conversations without losing track of the details.\n",
        "* **Strong Instruction Following:** The `-Instruct` fine-tuning means it's specifically designed to follow detailed instructions. You can provide it with a complex rubric or set of evaluation criteria (e.g., \"Score the response based on helpfulness, clarity, and factual accuracy, then provide a short rationale\"), and it will do a good job of adhering to that format.\n",
        "*   **Commercial Use:** The model is available for commercial use under the Llama 3.2 Community License, making it an attractive option for businesses and developers looking to build AI-powered products.\n",
        "\n",
        "### Weaknesses and Considerations (Where you need to be cautious)\n",
        "\n",
        "1.  **Limited Nuance and Depth:** This is the primary trade-off. For highly complex, subtle, or creative tasks (e.g., judging the quality of a poem, evaluating a complex legal argument, or assessing a sophisticated piece of code), a 3B model lacks the deep world knowledge and nuanced understanding of a much larger model (like a 70B or a GPT-4 class model). Its judgments on such topics will be more superficial.\n",
        "\n",
        "2.  **Susceptibility to Bias:** Like all LLMs, it can be prone to common evaluation biases, such as:\n",
        "    *   **Positional Bias:** Tending to prefer the first or second answer it's shown, regardless of quality.\n",
        "    *   **Verbosity Bias:** Preferring longer, more detailed answers even if they aren't more correct.\n",
        "    *   **Affirmation Bias:** Agreeing with the user's framing or the premise of the question.\n",
        "    These biases might be more pronounced in a smaller model.\n",
        "\n",
        "3.  **Fact-Checking Limitations:** A 3B model has a smaller knowledge base and is more likely to hallucinate or fail to identify factual errors in the texts it's judging. You cannot rely on it as a sole arbiter of factual accuracy.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dl0L6boElhDm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4D_3Auh7osc"
      },
      "outputs": [],
      "source": [
        "# Load the evaluation model and tokenizer (AI Judge)\n",
        "evaluation_model = \"meta-llama/Llama-3.2-3B-Instruct\" # \"alpindale/Llama-3.2-3B-Instruct\"\n",
        "eval_tokenizer = AutoTokenizer.from_pretrained(evaluation_model)\n",
        "eval_model = AutoModelForCausalLM.from_pretrained(\n",
        "    evaluation_model,\n",
        "    torch_dtype=dtype,\n",
        "    device_map=device,\n",
        "    use_cache=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UmScYdFOvz0",
        "outputId": "f739eb32-ed72-4b79-bce3-ba45f312dee8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:03<00:00,  6.28it/s]\n"
          ]
        }
      ],
      "source": [
        "# Function to generate the prompt for the AI judge\n",
        "def evaluation_prompt(question, expected_answer, generated_answer):\n",
        "  prompt = f\"\"\"You are an impartial evaluator.\n",
        "Your task is to determine if the \"Generated Answer\", even if too verbose, correctly answers the \"Question\".\n",
        "The \"Expected Answer\" is provided as a reference for the correct information.\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Expected Answer:\n",
        "{expected_answer}\n",
        "\n",
        "Generated Answer:\n",
        "{generated_answer}\n",
        "\n",
        "Is the \"Generated Answer\" correct? Please answer with \"Yes\" or \"No\".\n",
        "\"\"\"\n",
        "  return prompt\n",
        "\n",
        "# Evaluate generated answers using the AI judge\n",
        "ai_judge = []\n",
        "\n",
        "for i in tqdm(range(len(results_df))):\n",
        "  question = results_df.iloc[i]['question']\n",
        "  expected_answer = results_df.iloc[i]['expected_answer']\n",
        "  generated_answer = results_df.iloc[i]['generated_answer']\n",
        "  prompt = evaluation_prompt(question, expected_answer, generated_answer)\n",
        "\n",
        "  inputs = eval_tokenizer.apply_chat_template(\n",
        "            [{\"role\": \"user\", \"content\": prompt}],\n",
        "            tokenize=True,\n",
        "            add_generation_prompt=True,\n",
        "            return_tensors=\"pt\",\n",
        "        ).to(device)\n",
        "\n",
        "  # Generate a response from the AI judge\n",
        "  outputs = eval_model.generate(\n",
        "      inputs,\n",
        "      pad_token_id=eval_tokenizer.eos_token_id,\n",
        "      max_new_tokens=100,\n",
        "      temperature=0.1,\n",
        "      do_sample=True,\n",
        "  )\n",
        "\n",
        "  generated_token_ids = outputs[0, inputs.shape[-1] :]\n",
        "  generated_text = eval_tokenizer.decode(\n",
        "      generated_token_ids,\n",
        "      skip_special_tokens=True,\n",
        "  ).strip()\n",
        "\n",
        "  # Determine correctness based on the AI judge's response\n",
        "  if \"yes\" in generated_text.lower():\n",
        "    ai_judge.append(True)\n",
        "  else:\n",
        "    ai_judge.append(False)\n",
        "\n",
        "results_df[\"is_correct_ai_eval\"] = ai_judge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aff7ce6",
        "outputId": "fd82e9f4-24b4-4bdd-bcc0-d7462b7c068c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Keyword Matching Accuracy: 0.24\n",
            "Overall Semantic Similarity Accuracy (threshold=0.5): 0.52\n",
            "Overall AI Judge Accuracy: 0.32\n"
          ]
        }
      ],
      "source": [
        "# Calculate overall correctness metrics for each evaluation method\n",
        "overall_keyword_accuracy = results_df['is_correct_keyword'].mean()\n",
        "overall_semantic_accuracy = results_df['is_correct_semantic'].mean()\n",
        "overall_ai_judge_accuracy = results_df['is_correct_ai_eval'].mean()\n",
        "\n",
        "print(f\"Overall Keyword Matching Accuracy: {overall_keyword_accuracy:.2f}\")\n",
        "print(f\"Overall Semantic Similarity Accuracy (threshold=0.5): {overall_semantic_accuracy:.2f}\")\n",
        "print(f\"Overall AI Judge Accuracy: {overall_ai_judge_accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "bb165b21",
        "outputId": "67226562-b398-4c99-e2d9-6e8d99ef1f83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Keyword Matching Accuracy by Difficulty:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  difficulty  is_correct_keyword\n",
              "0       Easy            0.416667\n",
              "1       Hard            0.000000\n",
              "2     Medium            0.111111"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a57d8f3-f6bf-499a-aa5e-0c635f0e09a4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>difficulty</th>\n",
              "      <th>is_correct_keyword</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Easy</td>\n",
              "      <td>0.416667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hard</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Medium</td>\n",
              "      <td>0.111111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a57d8f3-f6bf-499a-aa5e-0c635f0e09a4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3a57d8f3-f6bf-499a-aa5e-0c635f0e09a4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3a57d8f3-f6bf-499a-aa5e-0c635f0e09a4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9e969eec-014d-4a92-8cbc-b2906f8fc8d6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9e969eec-014d-4a92-8cbc-b2906f8fc8d6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9e969eec-014d-4a92-8cbc-b2906f8fc8d6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_ea181651-854b-413e-8878-fd17f8822be6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('difficulty_analysis_keyword')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ea181651-854b-413e-8878-fd17f8822be6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('difficulty_analysis_keyword');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "difficulty_analysis_keyword",
              "summary": "{\n  \"name\": \"difficulty_analysis_keyword\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"difficulty\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Easy\",\n          \"Hard\",\n          \"Medium\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_correct_keyword\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2157625962542786,\n        \"min\": 0.0,\n        \"max\": 0.4166666666666667,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.4166666666666667,\n          0.0,\n          0.1111111111111111\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Semantic Similarity Accuracy by Difficulty (threshold=0.5):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  difficulty  is_correct_semantic\n",
              "0       Easy             0.833333\n",
              "1       Hard             0.250000\n",
              "2     Medium             0.222222"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-26ac8670-3331-476e-9c22-c66bb9b8d8dc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>difficulty</th>\n",
              "      <th>is_correct_semantic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Easy</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hard</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Medium</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26ac8670-3331-476e-9c22-c66bb9b8d8dc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-26ac8670-3331-476e-9c22-c66bb9b8d8dc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-26ac8670-3331-476e-9c22-c66bb9b8d8dc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d16aab45-1846-4a7f-8100-758a94398e22\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d16aab45-1846-4a7f-8100-758a94398e22')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d16aab45-1846-4a7f-8100-758a94398e22 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_82ea56c9-4bd9-4909-93e9-522fb17cd5ba\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('difficulty_analysis_semantic')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_82ea56c9-4bd9-4909-93e9-522fb17cd5ba button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('difficulty_analysis_semantic');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "difficulty_analysis_semantic",
              "summary": "{\n  \"name\": \"difficulty_analysis_semantic\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"difficulty\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Easy\",\n          \"Hard\",\n          \"Medium\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_correct_semantic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3450860213626708,\n        \"min\": 0.2222222222222222,\n        \"max\": 0.8333333333333334,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.8333333333333334,\n          0.25,\n          0.2222222222222222\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "AI Judge Accuracy by Difficulty:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  difficulty  is_correct_ai_eval\n",
              "0       Easy            0.583333\n",
              "1       Hard            0.000000\n",
              "2     Medium            0.111111"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09b93559-d31f-44b3-9a12-0e2f2517253e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>difficulty</th>\n",
              "      <th>is_correct_ai_eval</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Easy</td>\n",
              "      <td>0.583333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hard</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Medium</td>\n",
              "      <td>0.111111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09b93559-d31f-44b3-9a12-0e2f2517253e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-09b93559-d31f-44b3-9a12-0e2f2517253e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-09b93559-d31f-44b3-9a12-0e2f2517253e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9486a330-846f-4f8a-a430-c6ce0f45fd9f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9486a330-846f-4f8a-a430-c6ce0f45fd9f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9486a330-846f-4f8a-a430-c6ce0f45fd9f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_b0749647-0aff-46ca-8a49-b6e6fe9d84e4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('difficulty_analysis_ai_judge')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b0749647-0aff-46ca-8a49-b6e6fe9d84e4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('difficulty_analysis_ai_judge');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "difficulty_analysis_ai_judge",
              "summary": "{\n  \"name\": \"difficulty_analysis_ai_judge\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"difficulty\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Easy\",\n          \"Hard\",\n          \"Medium\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_correct_ai_eval\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.30973571636440245,\n        \"min\": 0.0,\n        \"max\": 0.5833333333333334,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5833333333333334,\n          0.0,\n          0.1111111111111111\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Analyze correctness by difficulty for each evaluation method\n",
        "difficulty_analysis_keyword = results_df.groupby('difficulty')['is_correct_keyword'].mean().reset_index()\n",
        "difficulty_analysis_semantic = results_df.groupby('difficulty')['is_correct_semantic'].mean().reset_index()\n",
        "difficulty_analysis_ai_judge = results_df.groupby('difficulty')['is_correct_ai_eval'].mean().reset_index()\n",
        "\n",
        "print(\"\\nKeyword Matching Accuracy by Difficulty:\")\n",
        "display(difficulty_analysis_keyword)\n",
        "\n",
        "print(\"\\nSemantic Similarity Accuracy by Difficulty (threshold=0.5):\")\n",
        "display(difficulty_analysis_semantic)\n",
        "\n",
        "print(\"\\nAI Judge Accuracy by Difficulty:\")\n",
        "display(difficulty_analysis_ai_judge)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate average perplexity by difficulty\n",
        "average_perplexity_by_difficulty = results_df.groupby('difficulty')['perplexity'].mean().reset_index()\n",
        "\n",
        "print(\"\\nAverage Perplexity by Difficulty:\")\n",
        "display(average_perplexity_by_difficulty)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "foR-X9Fe2jza",
        "outputId": "3d74fd31-4ff5-4855-efc8-1d52b71ae3b7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Perplexity by Difficulty:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  difficulty    perplexity\n",
              "0       Easy  2.359580e+07\n",
              "1       Hard  4.135771e+06\n",
              "2     Medium  1.541957e+09"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-decaea69-57d7-460f-80eb-a1d6ea9c43e3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>difficulty</th>\n",
              "      <th>perplexity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Easy</td>\n",
              "      <td>2.359580e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hard</td>\n",
              "      <td>4.135771e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Medium</td>\n",
              "      <td>1.541957e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-decaea69-57d7-460f-80eb-a1d6ea9c43e3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-decaea69-57d7-460f-80eb-a1d6ea9c43e3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-decaea69-57d7-460f-80eb-a1d6ea9c43e3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c2c70b69-f356-4413-997d-8c0d3bcc88e7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c2c70b69-f356-4413-997d-8c0d3bcc88e7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c2c70b69-f356-4413-997d-8c0d3bcc88e7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_681c3aec-ea42-4ad6-8916-ac724dc3535d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('average_perplexity_by_difficulty')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_681c3aec-ea42-4ad6-8916-ac724dc3535d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('average_perplexity_by_difficulty');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "average_perplexity_by_difficulty",
              "summary": "{\n  \"name\": \"average_perplexity_by_difficulty\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"difficulty\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Easy\",\n          \"Hard\",\n          \"Medium\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"perplexity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 882297661.5781121,\n        \"min\": 4135771.2351150513,\n        \"max\": 1541957232.921007,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          23595799.98864746,\n          4135771.2351150513,\n          1541957232.921007\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d8af88b9",
        "outputId": "4956b909-75bb-4d77-9d26-dd6d54c94c5d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                             question  \\\n",
              "0       Who created the character of Sherlock Holmes?   \n",
              "1        What is the name of Sherlock Holmes's enemy?   \n",
              "2                    Where does Sherlock Holmes live?   \n",
              "3               Who is Sherlock Holmes's best friend?   \n",
              "4       What is the name of Sherlock's older brother?   \n",
              "5           Who is the landlady of 221b Baker Street?   \n",
              "6   What musical instrument does Sherlock Holmes l...   \n",
              "7   In which Sherlock Holmes short story do we mee...   \n",
              "8   Which actor plays Sherlock Holmes in the TV se...   \n",
              "9                           Who did Dr. Watson marry?   \n",
              "10  What are the street boys called who run errand...   \n",
              "11  Who stars as Sherlock Holmes in the 2009 film ...   \n",
              "12  Who stars as Watson in the 2009 film Sherlock ...   \n",
              "13   What was the first Sherlock Holmes story titled?   \n",
              "14  Which 2020 film features the teenage sister of...   \n",
              "15          Where did Sherlock and Watson first meet?   \n",
              "16  When Sherlock Holmes retired, what hobby did h...   \n",
              "17       Where does Sherlock Holmes keep his tobacco?   \n",
              "18  What is the client's name in the short story \"...   \n",
              "19  What was the title of the short story publishe...   \n",
              "20  What was the first book released after everyon...   \n",
              "21                 What object is the Blue Carbuncle?   \n",
              "22        What is Sherlock Holmes's most famous line?   \n",
              "23  On what British TV channel is the series Sherl...   \n",
              "24  In The Hound Of The Baskervilles, what village...   \n",
              "\n",
              "                  expected_answer  \\\n",
              "0          Sir Arthur Conan Doyle   \n",
              "1              Professor Moriarty   \n",
              "2     221b Baker Street in London   \n",
              "3                 Dr. John Watson   \n",
              "4                  Mycroft Holmes   \n",
              "5                     Mrs. Hudson   \n",
              "6                      The violin   \n",
              "7            A Scandal In Bohemia   \n",
              "8            Benedict Cumberbatch   \n",
              "9                    Mary Morstan   \n",
              "10    The Baker Street Irregulars   \n",
              "11              Robert Downey Jr.   \n",
              "12                       Jude Law   \n",
              "13             A Study In Scarlet   \n",
              "14                   Enola Holmes   \n",
              "15     St. Bartholomew's hospital   \n",
              "16                     Beekeeping   \n",
              "17           In a Persian slipper   \n",
              "18                  John Openshaw   \n",
              "19              The Final Problem   \n",
              "20  The Hound Of The Baskervilles   \n",
              "21           A priceless gemstone   \n",
              "22  \"Elementary, my dear Watson.\"   \n",
              "23                        BBC One   \n",
              "24                        Grimpen   \n",
              "\n",
              "                                     generated_answer difficulty  \\\n",
              "0                                  Arthur Conan Doyle       Easy   \n",
              "1                                  Professor Moriarty       Easy   \n",
              "2                                  221B Baker Street.       Easy   \n",
              "3                                     Dr. John Watson       Easy   \n",
              "4                                            William.       Easy   \n",
              "5                                         Mrs. Hudson       Easy   \n",
              "6                                          The piano.       Easy   \n",
              "7                   The Adventure of the Dancing Men.     Medium   \n",
              "8                                Benedict Cumberbatch       Easy   \n",
              "9                                    Dr. John Watson.     Medium   \n",
              "10                                           Footmen.     Medium   \n",
              "11                                  Robert Downey Jr.       Easy   \n",
              "12                                       Daniel Craig       Easy   \n",
              "13                     The Hound of the Baskervilles.     Medium   \n",
              "14                                   Sherlock Holmes.       Easy   \n",
              "15                                   At Baker Street.     Medium   \n",
              "16                      He started collecting stamps.     Medium   \n",
              "17                                       In his pipe.       Hard   \n",
              "18       The clientâ€™s name is â€œThe Five Orange Pips.â€       Hard   \n",
              "19                      The Hound of the Baskervilles     Medium   \n",
              "20  â€œThe Hound of the Baskervillesâ€ by Arthur Cona...     Medium   \n",
              "21                                        A gemstone.     Medium   \n",
              "22                      â€œElementary, my dear Watson.â€       Easy   \n",
              "23                                               ITV.       Hard   \n",
              "24                                          Dartmoor.       Hard   \n",
              "\n",
              "      perplexity  is_correct_keyword  semantic_similarity  \\\n",
              "0   5.542700e+06               False             0.962578   \n",
              "1   7.715562e+07                True             1.000000   \n",
              "2   2.347797e+03               False             0.901767   \n",
              "3   6.184248e+04                True             1.000000   \n",
              "4   2.119035e+03               False             0.264208   \n",
              "5   2.227913e+05                True             1.000000   \n",
              "6   2.154550e+07               False             0.587473   \n",
              "7   5.332988e+05               False             0.200190   \n",
              "8   6.248456e+07                True             1.000000   \n",
              "9   2.064508e+04               False             0.315029   \n",
              "10  7.245704e+04               False             0.190314   \n",
              "11  5.730942e+07                True             1.000000   \n",
              "12  5.488912e+07               False             0.408639   \n",
              "13  9.896129e+09               False             0.277919   \n",
              "14  3.778870e+06               False             0.548724   \n",
              "15  2.983286e+06               False             0.305989   \n",
              "16  2.835507e+07               False             0.177777   \n",
              "17  9.870477e+06               False             0.303258   \n",
              "18  6.589662e+06               False             0.165419   \n",
              "19  3.905365e+09               False             0.125750   \n",
              "20  4.398400e+07                True             0.794517   \n",
              "21  1.730851e+05               False             0.836267   \n",
              "22  1.547218e+05               False             0.993280   \n",
              "23  3.426358e+02               False             0.626558   \n",
              "24  8.260330e+04               False             0.168748   \n",
              "\n",
              "    is_correct_semantic  is_correct_ai_eval  \n",
              "0                  True                True  \n",
              "1                  True                True  \n",
              "2                  True               False  \n",
              "3                  True                True  \n",
              "4                 False               False  \n",
              "5                  True                True  \n",
              "6                  True               False  \n",
              "7                 False               False  \n",
              "8                  True                True  \n",
              "9                 False               False  \n",
              "10                False               False  \n",
              "11                 True                True  \n",
              "12                False               False  \n",
              "13                False               False  \n",
              "14                 True               False  \n",
              "15                False               False  \n",
              "16                False               False  \n",
              "17                False               False  \n",
              "18                False               False  \n",
              "19                False               False  \n",
              "20                 True                True  \n",
              "21                 True               False  \n",
              "22                 True                True  \n",
              "23                 True               False  \n",
              "24                False               False  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6d56764-aa5c-46ab-978a-c070bd69f7e6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>expected_answer</th>\n",
              "      <th>generated_answer</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>is_correct_keyword</th>\n",
              "      <th>semantic_similarity</th>\n",
              "      <th>is_correct_semantic</th>\n",
              "      <th>is_correct_ai_eval</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Who created the character of Sherlock Holmes?</td>\n",
              "      <td>Sir Arthur Conan Doyle</td>\n",
              "      <td>Arthur Conan Doyle</td>\n",
              "      <td>Easy</td>\n",
              "      <td>5.542700e+06</td>\n",
              "      <td>False</td>\n",
              "      <td>0.962578</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the name of Sherlock Holmes's enemy?</td>\n",
              "      <td>Professor Moriarty</td>\n",
              "      <td>Professor Moriarty</td>\n",
              "      <td>Easy</td>\n",
              "      <td>7.715562e+07</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Where does Sherlock Holmes live?</td>\n",
              "      <td>221b Baker Street in London</td>\n",
              "      <td>221B Baker Street.</td>\n",
              "      <td>Easy</td>\n",
              "      <td>2.347797e+03</td>\n",
              "      <td>False</td>\n",
              "      <td>0.901767</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Who is Sherlock Holmes's best friend?</td>\n",
              "      <td>Dr. John Watson</td>\n",
              "      <td>Dr. John Watson</td>\n",
              "      <td>Easy</td>\n",
              "      <td>6.184248e+04</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the name of Sherlock's older brother?</td>\n",
              "      <td>Mycroft Holmes</td>\n",
              "      <td>William.</td>\n",
              "      <td>Easy</td>\n",
              "      <td>2.119035e+03</td>\n",
              "      <td>False</td>\n",
              "      <td>0.264208</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Who is the landlady of 221b Baker Street?</td>\n",
              "      <td>Mrs. Hudson</td>\n",
              "      <td>Mrs. Hudson</td>\n",
              "      <td>Easy</td>\n",
              "      <td>2.227913e+05</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What musical instrument does Sherlock Holmes l...</td>\n",
              "      <td>The violin</td>\n",
              "      <td>The piano.</td>\n",
              "      <td>Easy</td>\n",
              "      <td>2.154550e+07</td>\n",
              "      <td>False</td>\n",
              "      <td>0.587473</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>In which Sherlock Holmes short story do we mee...</td>\n",
              "      <td>A Scandal In Bohemia</td>\n",
              "      <td>The Adventure of the Dancing Men.</td>\n",
              "      <td>Medium</td>\n",
              "      <td>5.332988e+05</td>\n",
              "      <td>False</td>\n",
              "      <td>0.200190</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Which actor plays Sherlock Holmes in the TV se...</td>\n",
              "      <td>Benedict Cumberbatch</td>\n",
              "      <td>Benedict Cumberbatch</td>\n",
              "      <td>Easy</td>\n",
              "      <td>6.248456e+07</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Who did Dr. Watson marry?</td>\n",
              "      <td>Mary Morstan</td>\n",
              "      <td>Dr. John Watson.</td>\n",
              "      <td>Medium</td>\n",
              "      <td>2.064508e+04</td>\n",
              "      <td>False</td>\n",
              "      <td>0.315029</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What are the street boys called who run errand...</td>\n",
              "      <td>The Baker Street Irregulars</td>\n",
              "      <td>Footmen.</td>\n",
              "      <td>Medium</td>\n",
              "      <td>7.245704e+04</td>\n",
              "      <td>False</td>\n",
              "      <td>0.190314</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Who stars as Sherlock Holmes in the 2009 film ...</td>\n",
              "      <td>Robert Downey Jr.</td>\n",
              "      <td>Robert Downey Jr.</td>\n",
              "      <td>Easy</td>\n",
              "      <td>5.730942e+07</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Who stars as Watson in the 2009 film Sherlock ...</td>\n",
              "      <td>Jude Law</td>\n",
              "      <td>Daniel Craig</td>\n",
              "      <td>Easy</td>\n",
              "      <td>5.488912e+07</td>\n",
              "      <td>False</td>\n",
              "      <td>0.408639</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What was the first Sherlock Holmes story titled?</td>\n",
              "      <td>A Study In Scarlet</td>\n",
              "      <td>The Hound of the Baskervilles.</td>\n",
              "      <td>Medium</td>\n",
              "      <td>9.896129e+09</td>\n",
              "      <td>False</td>\n",
              "      <td>0.277919</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Which 2020 film features the teenage sister of...</td>\n",
              "      <td>Enola Holmes</td>\n",
              "      <td>Sherlock Holmes.</td>\n",
              "      <td>Easy</td>\n",
              "      <td>3.778870e+06</td>\n",
              "      <td>False</td>\n",
              "      <td>0.548724</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Where did Sherlock and Watson first meet?</td>\n",
              "      <td>St. Bartholomew's hospital</td>\n",
              "      <td>At Baker Street.</td>\n",
              "      <td>Medium</td>\n",
              "      <td>2.983286e+06</td>\n",
              "      <td>False</td>\n",
              "      <td>0.305989</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>When Sherlock Holmes retired, what hobby did h...</td>\n",
              "      <td>Beekeeping</td>\n",
              "      <td>He started collecting stamps.</td>\n",
              "      <td>Medium</td>\n",
              "      <td>2.835507e+07</td>\n",
              "      <td>False</td>\n",
              "      <td>0.177777</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Where does Sherlock Holmes keep his tobacco?</td>\n",
              "      <td>In a Persian slipper</td>\n",
              "      <td>In his pipe.</td>\n",
              "      <td>Hard</td>\n",
              "      <td>9.870477e+06</td>\n",
              "      <td>False</td>\n",
              "      <td>0.303258</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>What is the client's name in the short story \"...</td>\n",
              "      <td>John Openshaw</td>\n",
              "      <td>The clientâ€™s name is â€œThe Five Orange Pips.â€</td>\n",
              "      <td>Hard</td>\n",
              "      <td>6.589662e+06</td>\n",
              "      <td>False</td>\n",
              "      <td>0.165419</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>What was the title of the short story publishe...</td>\n",
              "      <td>The Final Problem</td>\n",
              "      <td>The Hound of the Baskervilles</td>\n",
              "      <td>Medium</td>\n",
              "      <td>3.905365e+09</td>\n",
              "      <td>False</td>\n",
              "      <td>0.125750</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>What was the first book released after everyon...</td>\n",
              "      <td>The Hound Of The Baskervilles</td>\n",
              "      <td>â€œThe Hound of the Baskervillesâ€ by Arthur Cona...</td>\n",
              "      <td>Medium</td>\n",
              "      <td>4.398400e+07</td>\n",
              "      <td>True</td>\n",
              "      <td>0.794517</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>What object is the Blue Carbuncle?</td>\n",
              "      <td>A priceless gemstone</td>\n",
              "      <td>A gemstone.</td>\n",
              "      <td>Medium</td>\n",
              "      <td>1.730851e+05</td>\n",
              "      <td>False</td>\n",
              "      <td>0.836267</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>What is Sherlock Holmes's most famous line?</td>\n",
              "      <td>\"Elementary, my dear Watson.\"</td>\n",
              "      <td>â€œElementary, my dear Watson.â€</td>\n",
              "      <td>Easy</td>\n",
              "      <td>1.547218e+05</td>\n",
              "      <td>False</td>\n",
              "      <td>0.993280</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>On what British TV channel is the series Sherl...</td>\n",
              "      <td>BBC One</td>\n",
              "      <td>ITV.</td>\n",
              "      <td>Hard</td>\n",
              "      <td>3.426358e+02</td>\n",
              "      <td>False</td>\n",
              "      <td>0.626558</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>In The Hound Of The Baskervilles, what village...</td>\n",
              "      <td>Grimpen</td>\n",
              "      <td>Dartmoor.</td>\n",
              "      <td>Hard</td>\n",
              "      <td>8.260330e+04</td>\n",
              "      <td>False</td>\n",
              "      <td>0.168748</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6d56764-aa5c-46ab-978a-c070bd69f7e6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e6d56764-aa5c-46ab-978a-c070bd69f7e6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e6d56764-aa5c-46ab-978a-c070bd69f7e6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-039617e7-5cf7-4942-8bb0-c61d55efdd9c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-039617e7-5cf7-4942-8bb0-c61d55efdd9c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-039617e7-5cf7-4942-8bb0-c61d55efdd9c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_63938b71-86bf-4eb6-bcd8-8b6300d6fb80\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_63938b71-86bf-4eb6-bcd8-8b6300d6fb80 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"Which actor plays Sherlock Holmes in the TV series Sherlock?\",\n          \"When Sherlock Holmes retired, what hobby did he take up?\",\n          \"Who created the character of Sherlock Holmes?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"expected_answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"Benedict Cumberbatch\",\n          \"Beekeeping\",\n          \"Sir Arthur Conan Doyle\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"generated_answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"Benedict Cumberbatch\",\n          \"He started collecting stamps.\",\n          \"Arthur Conan Doyle\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"difficulty\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Easy\",\n          \"Medium\",\n          \"Hard\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"perplexity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2093292297.9465072,\n        \"min\": 342.6357727050781,\n        \"max\": 9896128512.0,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          62484556.0,\n          28355072.0,\n          5542699.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_correct_keyword\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"semantic_similarity\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.9625775218009949,\n          0.17777687311172485\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_correct_semantic\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_correct_ai_eval\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Display the detailed results DataFrame\n",
        "display(results_df)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv (3.12.9)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}