{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmassaron/fine-tuning-workshop/blob/main/sherlock_knowledge_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhNrI5idd_vH",
        "outputId": "66594aca-2169-4c70-bd17-0904ec9c0ec1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Sep 25 00:37:31 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.163.01             Driver Version: 550.163.01     CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 3090        Off |   00000000:01:00.0  On |                  N/A |\n",
            "| 30%   36C    P5             33W /  350W |     382MiB /  24576MiB |     36%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A      2018      G   /usr/lib/xorg/Xorg                            102MiB |\n",
            "|    0   N/A  N/A      2164      G   /usr/bin/gnome-shell                          134MiB |\n",
            "|    0   N/A  N/A      4735      G   /usr/share/code/code                          134MiB |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check the GPU information\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnjgsKN_esrw"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries for model training and evaluation\n",
        "#%%capture\n",
        "#!pip install -U transformers trl accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbszOixGedSt",
        "outputId": "1b1326fe-82e0-47fd-e5d0-94ae33116084"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using PyTorch version: 2.8.0+cu128\n",
            "Using TRL version: 0.22.2\n",
            "Using bitsandbytes version: 0.47.0\n"
          ]
        }
      ],
      "source": [
        "# Import and print the versions of the installed libraries\n",
        "import torch\n",
        "import trl\n",
        "import bitsandbytes\n",
        "\n",
        "print(f\"Using PyTorch version: {torch.__version__}\")\n",
        "print(f\"Using TRL version: {trl.__version__}\")\n",
        "print(f\"Using bitsandbytes version: {bitsandbytes.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YfeOmO0cfNGh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 09-25 00:37:35 [__init__.py:216] Automatically detected platform cuda.\n"
          ]
        }
      ],
      "source": [
        "# Import various libraries needed for data handling, model loading, and training\n",
        "import os\n",
        "import gc\n",
        "import warnings\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from datasets import Dataset, load_dataset\n",
        "from huggingface_hub import login\n",
        "from peft import LoraConfig\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from trl import GRPOConfig, GRPOTrainer, SFTConfig, SFTTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CrTseGUkffTN"
      },
      "outputs": [],
      "source": [
        "# Define configuration parameters for the model and data\n",
        "class Config:\n",
        "    \"\"\"Configuration parameters\"\"\"\n",
        "\n",
        "    SIZE = \"3-1b\"\n",
        "    MODEL_NAME = f\"google/gemma-{SIZE}-it\"\n",
        "\n",
        "    max_prompt_length = 352\n",
        "    max_completion_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0_hM-990eqrr"
      },
      "outputs": [],
      "source": [
        "# Initialization script to set up the environment and Hugging Face login\n",
        "def init():\n",
        "    \"\"\"Initialization script\"\"\"\n",
        "    os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"0\"\n",
        "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
        "\n",
        "    # It is recommended to set the HF_TOKEN as an environment variable\n",
        "    token = os.environ.get(\"HF_TOKEN\")\n",
        "    if token:\n",
        "        login(token=token)\n",
        "    else:\n",
        "      try:\n",
        "        from google.colab import userdata\n",
        "        # Retrieve your Hugging Face token from Colab's secrets manager\n",
        "        # The name 'HF_TOKEN' should match the name you used in the secrets tab\n",
        "        hf_token = userdata.get('HF_TOKEN')\n",
        "\n",
        "        # Check if the token was successfully retrieved\n",
        "        if hf_token:\n",
        "            # Log in to Hugging Face using the retrieved token\n",
        "            # The `add_to_git_credential=True` argument is optional and useful if you plan to push models to the Hub\n",
        "            login(token=hf_token, add_to_git_credential=True)\n",
        "            print(\"Hugging Face login successful using Google Colab secrets!\")\n",
        "        else:\n",
        "            print(\"Error: HF_TOKEN not found in Google Colab secrets or is empty.\")\n",
        "            print(\"Please ensure you have created a secret named 'HF_TOKEN' in the 'Secrets' tab (🔑) on the left sidebar.\")\n",
        "      except:\n",
        "        print(\"HF_TOKEN not set. You might need to log in manually.\")\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def is_bfloat16_supported():\n",
        "    \"\"\"Checks if the current device supports bfloat16.\"\"\"\n",
        "    return torch.cuda.is_available() and torch.cuda.get_device_capability(0)[0] >= 8\n",
        "\n",
        "\n",
        "def info_device():\n",
        "    \"\"\"Get device for PyTorch\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "    return device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lW6ft5_SfOV5",
        "outputId": "36ada8c2-ec90-47f7-b3b2-6411560311e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Using dtype: torch.bfloat16\n"
          ]
        }
      ],
      "source": [
        "# Initialize the environment, get parameters, device, and data type\n",
        "init()\n",
        "params = Config()\n",
        "device = info_device()\n",
        "dtype = torch.bfloat16 if is_bfloat16_supported() else torch.float16\n",
        "print(f\"Using dtype: {dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1OtC1THhf0VS"
      },
      "outputs": [],
      "source": [
        "# Function to load dataset from Hugging Face Hub\n",
        "def get_data(repo_id, mapping_func=None, split=\"train\"):\n",
        "    \"\"\"Upload HF dataset\"\"\"\n",
        "    data = load_dataset(repo_id, cache_dir=\"/tmp\")[split]\n",
        "    if mapping_func:\n",
        "      data = data.map(mapping_func)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7ty8thGnhB1M"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2baa134ec13740da93d6f06b98a4fd86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/25 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the Sherlock QA dataset\n",
        "data = get_data(repo_id=\"lmassaron/Sherlock_QA_test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19ihvnylhGEE",
        "outputId": "83976fdf-658e-4321-b36f-35ab4c43d4c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Question', 'Answer', 'Difficulty'],\n",
              "    num_rows: 25\n",
              "})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the loaded dataset information\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ag2jIkzshLAK"
      },
      "outputs": [],
      "source": [
        "# Load the tokenizer and model from Hugging Face\n",
        "tokenizer = AutoTokenizer.from_pretrained(params.MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    params.MODEL_NAME,\n",
        "    torch_dtype=dtype,\n",
        "    device_map=device,\n",
        "    use_cache=True\n",
        ")\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhzjOp95hXVG",
        "outputId": "902d01c6-d58c-488c-ad8d-ba937b31fdca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating Samples:   0%|          | 0/25 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:   4%|▍         | 1/25 [00:21<08:46, 21.95s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:   8%|▊         | 2/25 [00:53<10:36, 27.66s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:  16%|█▌        | 4/25 [00:53<03:37, 10.36s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:  24%|██▍       | 6/25 [01:11<03:03,  9.65s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:  32%|███▏      | 8/25 [01:11<01:38,  5.79s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:  40%|████      | 10/25 [01:11<00:55,  3.70s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:  48%|████▊     | 12/25 [01:29<01:10,  5.43s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:  56%|█████▌    | 14/25 [01:29<00:40,  3.66s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:  64%|██████▍   | 16/25 [01:29<00:22,  2.52s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:  72%|███████▏  | 18/25 [01:29<00:12,  1.74s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:  76%|███████▌  | 19/25 [01:47<00:27,  4.66s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:  80%|████████  | 20/25 [02:04<00:36,  7.36s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:  84%|████████▍ | 21/25 [02:05<00:22,  5.71s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:  92%|█████████▏| 23/25 [02:05<00:06,  3.48s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples: 100%|██████████| 25/25 [02:05<00:00,  5.01s/it]\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the dataset and store results\n",
        "temperature = 0\n",
        "results_list = []\n",
        "instructions = \"\\nBriefly, just give the straight answer to the question.\"\n",
        "\n",
        "# It's good practice to set the pad_token if it's not already set.\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "for row in tqdm(data, desc=\"Evaluating Samples\"):\n",
        "  question = row['Question']\n",
        "  answer = row['Answer']\n",
        "  difficulty = row['Difficulty']\n",
        "\n",
        "  # Tokenize the input and get both input_ids and attention_mask\n",
        "  inputs = tokenizer.apply_chat_template(\n",
        "            [{\"role\": \"user\", \"content\": question + instructions}],\n",
        "            tokenize=True,\n",
        "            add_generation_prompt=True,  # Crucial for telling the model it's its turn to speak\n",
        "            return_tensors=\"pt\",\n",
        "            return_dict=True  # Ensure the output is a dictionary\n",
        "        ).to(device)\n",
        "\n",
        "  # Prepare arguments for the generate function\n",
        "  generation_kwargs = {\n",
        "      \"pad_token_id\": tokenizer.eos_token_id,\n",
        "      \"max_new_tokens\": params.max_completion_length,\n",
        "      \"do_sample\": temperature > 0\n",
        "  }\n",
        "\n",
        "  # Only add temperature to kwargs if sampling is enabled\n",
        "  if generation_kwargs[\"do_sample\"]:\n",
        "      generation_kwargs[\"temperature\"] = temperature\n",
        "\n",
        "  # Generate a completion from the model, passing the attention_mask\n",
        "  outputs = model.generate(\n",
        "      inputs.input_ids, # Pass input_ids explicitly\n",
        "      attention_mask=inputs.attention_mask, # Pass the attention mask\n",
        "      **generation_kwargs\n",
        "      )\n",
        "\n",
        "  generated_token_ids = outputs[0, inputs.input_ids.shape[-1] :]\n",
        "  generated_text = tokenizer.decode(\n",
        "      generated_token_ids,\n",
        "      skip_special_tokens=True,\n",
        "  ).strip()\n",
        "\n",
        "  results_list.append({\n",
        "      'question': question,\n",
        "      'expected_answer': answer,\n",
        "      'generated_answer': generated_text,\n",
        "      'difficulty': difficulty\n",
        "  })\n",
        "\n",
        "results_df = pd.DataFrame(results_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WkXFPkxWRztL"
      },
      "outputs": [],
      "source": [
        "# Delete the model and tokenizer to free up GPU memory\n",
        "del [model, tokenizer]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MypZobdjqjYg"
      },
      "outputs": [],
      "source": [
        "# Evaluate correctness based on keyword matching\n",
        "def evaluate_keyword(row):\n",
        "    return row['expected_answer'].lower() in row['generated_answer'].lower()\n",
        "\n",
        "results_df['is_correct_keyword'] = results_df.apply(evaluate_keyword, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-b62iLlS1cJb"
      },
      "outputs": [],
      "source": [
        "# Evaluate correctness based on semantic similarity using Sentence-BERT\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Load the Sentence-BERT model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Encode the expected and generated answers into embeddings\n",
        "expected_embeddings = model.encode(results_df['expected_answer'].tolist(), convert_to_tensor=True)\n",
        "generated_embeddings = model.encode(results_df['generated_answer'].tolist(), convert_to_tensor=True)\n",
        "\n",
        "# Calculate cosine similarity between embeddings\n",
        "cosine_scores = util.cos_sim(expected_embeddings, generated_embeddings)\n",
        "cosine_scores = np.array(cosine_scores.cpu())\n",
        "\n",
        "# Store the semantic similarity scores\n",
        "results_df['semantic_similarity'] = [cosine_scores[i][i] for i in range(len(cosine_scores))]\n",
        "\n",
        "# Determine correctness based on a similarity threshold\n",
        "similarity_threshold = 0.5\n",
        "results_df['is_correct_semantic'] = results_df['semantic_similarity'] >= similarity_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EMCEuo_TR352"
      },
      "outputs": [],
      "source": [
        "# Delete the Sentence-BERT model to free up memory\n",
        "del [model]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "B4D_3Auh7osc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83bff5a4334443c8909604ae5c3d42e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the evaluation model and tokenizer (AI Judge)\n",
        "evaluation_model = \"meta-llama/Llama-3.2-3B-Instruct\" # \"alpindale/Llama-3.2-3B-Instruct\"\n",
        "eval_tokenizer = AutoTokenizer.from_pretrained(evaluation_model)\n",
        "eval_model = AutoModelForCausalLM.from_pretrained(\n",
        "    evaluation_model,\n",
        "    torch_dtype=dtype,\n",
        "    device_map=device,\n",
        "    use_cache=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UmScYdFOvz0",
        "outputId": "a9cb3d83-3e14-4279-8ee0-15e1bb221521"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "100%|██████████| 25/25 [00:02<00:00, 11.64it/s]\n"
          ]
        }
      ],
      "source": [
        "# Function to generate the prompt for the AI judge\n",
        "def evaluation_prompt(question, expected_answer, generated_answer):\n",
        "  prompt = f\"\"\"You are an impartial evaluator.\n",
        "Your task is to determine if the \"Generated Answer\", even if too verbose, correctly answers the \"Question\".\n",
        "The \"Expected Answer\" is provided as a reference for the correct information.\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Expected Answer:\n",
        "{expected_answer}\n",
        "\n",
        "Generated Answer:\n",
        "{generated_answer}\n",
        "\n",
        "Is the \"Generated Answer\" correct? Please answer with \"Yes\" or \"No\".\n",
        "\"\"\"\n",
        "  return prompt\n",
        "\n",
        "# Evaluate generated answers using the AI judge\n",
        "ai_judge = []\n",
        "\n",
        "for i in tqdm(range(len(results_df))):\n",
        "  question = results_df.iloc[i]['question']\n",
        "  expected_answer = results_df.iloc[i]['expected_answer']\n",
        "  generated_answer = results_df.iloc[i]['generated_answer']\n",
        "  prompt = evaluation_prompt(question, expected_answer, generated_answer)\n",
        "\n",
        "  inputs = eval_tokenizer.apply_chat_template(\n",
        "            [{\"role\": \"user\", \"content\": prompt}],\n",
        "            tokenize=True,\n",
        "            add_generation_prompt=True,\n",
        "            return_tensors=\"pt\",\n",
        "        ).to(device)\n",
        "\n",
        "  # Generate a response from the AI judge\n",
        "  outputs = eval_model.generate(\n",
        "      inputs,\n",
        "      pad_token_id=eval_tokenizer.eos_token_id,\n",
        "      max_new_tokens=100,\n",
        "      temperature=0.1,\n",
        "      do_sample=True,\n",
        "  )\n",
        "\n",
        "  generated_token_ids = outputs[0, inputs.shape[-1] :]\n",
        "  generated_text = eval_tokenizer.decode(\n",
        "      generated_token_ids,\n",
        "      skip_special_tokens=True,\n",
        "  ).strip()\n",
        "\n",
        "  # Determine correctness based on the AI judge's response\n",
        "  if \"yes\" in generated_text.lower():\n",
        "    ai_judge.append(True)\n",
        "  else:\n",
        "    ai_judge.append(False)\n",
        "\n",
        "results_df[\"is_correct_ai_eval\"] = ai_judge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aff7ce6",
        "outputId": "d676269a-4847-47b5-ca2f-80dd0f4c9553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Keyword Matching Accuracy: 0.24\n",
            "Overall Semantic Similarity Accuracy (threshold=0.5): 0.48\n",
            "Overall AI Judge Accuracy: 0.32\n"
          ]
        }
      ],
      "source": [
        "# Calculate overall correctness metrics for each evaluation method\n",
        "overall_keyword_accuracy = results_df['is_correct_keyword'].mean()\n",
        "overall_semantic_accuracy = results_df['is_correct_semantic'].mean()\n",
        "overall_ai_judge_accuracy = results_df['is_correct_ai_eval'].mean()\n",
        "\n",
        "print(f\"Overall Keyword Matching Accuracy: {overall_keyword_accuracy:.2f}\")\n",
        "print(f\"Overall Semantic Similarity Accuracy (threshold=0.5): {overall_semantic_accuracy:.2f}\")\n",
        "print(f\"Overall AI Judge Accuracy: {overall_ai_judge_accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "bb165b21",
        "outputId": "543b9bc6-e966-4752-f51a-2ee416db1d42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Keyword Matching Accuracy by Difficulty:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>difficulty</th>\n",
              "      <th>is_correct_keyword</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Easy</td>\n",
              "      <td>0.416667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hard</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Medium</td>\n",
              "      <td>0.111111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  difficulty  is_correct_keyword\n",
              "0       Easy            0.416667\n",
              "1       Hard            0.000000\n",
              "2     Medium            0.111111"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Semantic Similarity Accuracy by Difficulty (threshold=0.5):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>difficulty</th>\n",
              "      <th>is_correct_semantic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Easy</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hard</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Medium</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  difficulty  is_correct_semantic\n",
              "0       Easy             0.750000\n",
              "1       Hard             0.250000\n",
              "2     Medium             0.222222"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "AI Judge Accuracy by Difficulty:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>difficulty</th>\n",
              "      <th>is_correct_ai_eval</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Easy</td>\n",
              "      <td>0.583333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hard</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Medium</td>\n",
              "      <td>0.111111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  difficulty  is_correct_ai_eval\n",
              "0       Easy            0.583333\n",
              "1       Hard            0.000000\n",
              "2     Medium            0.111111"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Analyze correctness by difficulty for each evaluation method\n",
        "difficulty_analysis_keyword = results_df.groupby('difficulty')['is_correct_keyword'].mean().reset_index()\n",
        "difficulty_analysis_semantic = results_df.groupby('difficulty')['is_correct_semantic'].mean().reset_index()\n",
        "difficulty_analysis_ai_judge = results_df.groupby('difficulty')['is_correct_ai_eval'].mean().reset_index()\n",
        "\n",
        "print(\"\\nKeyword Matching Accuracy by Difficulty:\")\n",
        "display(difficulty_analysis_keyword)\n",
        "\n",
        "print(\"\\nSemantic Similarity Accuracy by Difficulty (threshold=0.5):\")\n",
        "display(difficulty_analysis_semantic)\n",
        "\n",
        "print(\"\\nAI Judge Accuracy by Difficulty:\")\n",
        "display(difficulty_analysis_ai_judge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d8af88b9",
        "outputId": "314c1dc7-e013-40e4-a191-5cf2a2a04422"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>expected_answer</th>\n",
              "      <th>generated_answer</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>is_correct_keyword</th>\n",
              "      <th>semantic_similarity</th>\n",
              "      <th>is_correct_semantic</th>\n",
              "      <th>is_correct_ai_eval</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Who created the character of Sherlock Holmes?</td>\n",
              "      <td>Sir Arthur Conan Doyle</td>\n",
              "      <td>Arthur Conan Doyle</td>\n",
              "      <td>Easy</td>\n",
              "      <td>False</td>\n",
              "      <td>0.962577</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the name of Sherlock Holmes's enemy?</td>\n",
              "      <td>Professor Moriarty</td>\n",
              "      <td>Professor Moriarty</td>\n",
              "      <td>Easy</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Where does Sherlock Holmes live?</td>\n",
              "      <td>221b Baker Street in London</td>\n",
              "      <td>221B Baker Street.</td>\n",
              "      <td>Easy</td>\n",
              "      <td>False</td>\n",
              "      <td>0.901767</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Who is Sherlock Holmes's best friend?</td>\n",
              "      <td>Dr. John Watson</td>\n",
              "      <td>Dr. John Watson</td>\n",
              "      <td>Easy</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the name of Sherlock's older brother?</td>\n",
              "      <td>Mycroft Holmes</td>\n",
              "      <td>William.</td>\n",
              "      <td>Easy</td>\n",
              "      <td>False</td>\n",
              "      <td>0.264208</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Who is the landlady of 221b Baker Street?</td>\n",
              "      <td>Mrs. Hudson</td>\n",
              "      <td>Mrs. Hudson</td>\n",
              "      <td>Easy</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What musical instrument does Sherlock Holmes l...</td>\n",
              "      <td>The violin</td>\n",
              "      <td>The piano.</td>\n",
              "      <td>Easy</td>\n",
              "      <td>False</td>\n",
              "      <td>0.587473</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>In which Sherlock Holmes short story do we mee...</td>\n",
              "      <td>A Scandal In Bohemia</td>\n",
              "      <td>The Adventure of the Dancing Men.</td>\n",
              "      <td>Medium</td>\n",
              "      <td>False</td>\n",
              "      <td>0.200190</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Which actor plays Sherlock Holmes in the TV se...</td>\n",
              "      <td>Benedict Cumberbatch</td>\n",
              "      <td>Benedict Cumberbatch</td>\n",
              "      <td>Easy</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Who did Dr. Watson marry?</td>\n",
              "      <td>Mary Morstan</td>\n",
              "      <td>Dr. John Watson.</td>\n",
              "      <td>Medium</td>\n",
              "      <td>False</td>\n",
              "      <td>0.315029</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What are the street boys called who run errand...</td>\n",
              "      <td>The Baker Street Irregulars</td>\n",
              "      <td>Footmen.</td>\n",
              "      <td>Medium</td>\n",
              "      <td>False</td>\n",
              "      <td>0.190314</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Who stars as Sherlock Holmes in the 2009 film ...</td>\n",
              "      <td>Robert Downey Jr.</td>\n",
              "      <td>Robert Downey Jr.</td>\n",
              "      <td>Easy</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Who stars as Watson in the 2009 film Sherlock ...</td>\n",
              "      <td>Jude Law</td>\n",
              "      <td>Daniel Craig</td>\n",
              "      <td>Easy</td>\n",
              "      <td>False</td>\n",
              "      <td>0.408639</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What was the first Sherlock Holmes story titled?</td>\n",
              "      <td>A Study In Scarlet</td>\n",
              "      <td>The Hound of the Baskervilles.</td>\n",
              "      <td>Medium</td>\n",
              "      <td>False</td>\n",
              "      <td>0.277919</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Which 2020 film features the teenage sister of...</td>\n",
              "      <td>Enola Holmes</td>\n",
              "      <td>Sherlock Holmes: A Game of Shadows</td>\n",
              "      <td>Easy</td>\n",
              "      <td>False</td>\n",
              "      <td>0.403840</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Where did Sherlock and Watson first meet?</td>\n",
              "      <td>St. Bartholomew's hospital</td>\n",
              "      <td>At Baker Street.</td>\n",
              "      <td>Medium</td>\n",
              "      <td>False</td>\n",
              "      <td>0.305989</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>When Sherlock Holmes retired, what hobby did h...</td>\n",
              "      <td>Beekeeping</td>\n",
              "      <td>He started collecting stamps.</td>\n",
              "      <td>Medium</td>\n",
              "      <td>False</td>\n",
              "      <td>0.177777</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Where does Sherlock Holmes keep his tobacco?</td>\n",
              "      <td>In a Persian slipper</td>\n",
              "      <td>In his pipe.</td>\n",
              "      <td>Hard</td>\n",
              "      <td>False</td>\n",
              "      <td>0.303259</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>What is the client's name in the short story \"...</td>\n",
              "      <td>John Openshaw</td>\n",
              "      <td>The client’s name is “The Five Orange Pips.”</td>\n",
              "      <td>Hard</td>\n",
              "      <td>False</td>\n",
              "      <td>0.165419</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>What was the title of the short story publishe...</td>\n",
              "      <td>The Final Problem</td>\n",
              "      <td>The Hound of the Baskervilles</td>\n",
              "      <td>Medium</td>\n",
              "      <td>False</td>\n",
              "      <td>0.125750</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>What was the first book released after everyon...</td>\n",
              "      <td>The Hound Of The Baskervilles</td>\n",
              "      <td>“The Hound of the Baskervilles” by Arthur Cona...</td>\n",
              "      <td>Medium</td>\n",
              "      <td>True</td>\n",
              "      <td>0.794517</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>What object is the Blue Carbuncle?</td>\n",
              "      <td>A priceless gemstone</td>\n",
              "      <td>A gemstone.</td>\n",
              "      <td>Medium</td>\n",
              "      <td>False</td>\n",
              "      <td>0.836267</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>What is Sherlock Holmes's most famous line?</td>\n",
              "      <td>\"Elementary, my dear Watson.\"</td>\n",
              "      <td>“Elementary, my dear Watson.”</td>\n",
              "      <td>Easy</td>\n",
              "      <td>False</td>\n",
              "      <td>0.993280</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>On what British TV channel is the series Sherl...</td>\n",
              "      <td>BBC One</td>\n",
              "      <td>ITV.</td>\n",
              "      <td>Hard</td>\n",
              "      <td>False</td>\n",
              "      <td>0.626558</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>In The Hound Of The Baskervilles, what village...</td>\n",
              "      <td>Grimpen</td>\n",
              "      <td>Dartmoor.</td>\n",
              "      <td>Hard</td>\n",
              "      <td>False</td>\n",
              "      <td>0.168748</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question  \\\n",
              "0       Who created the character of Sherlock Holmes?   \n",
              "1        What is the name of Sherlock Holmes's enemy?   \n",
              "2                    Where does Sherlock Holmes live?   \n",
              "3               Who is Sherlock Holmes's best friend?   \n",
              "4       What is the name of Sherlock's older brother?   \n",
              "5           Who is the landlady of 221b Baker Street?   \n",
              "6   What musical instrument does Sherlock Holmes l...   \n",
              "7   In which Sherlock Holmes short story do we mee...   \n",
              "8   Which actor plays Sherlock Holmes in the TV se...   \n",
              "9                           Who did Dr. Watson marry?   \n",
              "10  What are the street boys called who run errand...   \n",
              "11  Who stars as Sherlock Holmes in the 2009 film ...   \n",
              "12  Who stars as Watson in the 2009 film Sherlock ...   \n",
              "13   What was the first Sherlock Holmes story titled?   \n",
              "14  Which 2020 film features the teenage sister of...   \n",
              "15          Where did Sherlock and Watson first meet?   \n",
              "16  When Sherlock Holmes retired, what hobby did h...   \n",
              "17       Where does Sherlock Holmes keep his tobacco?   \n",
              "18  What is the client's name in the short story \"...   \n",
              "19  What was the title of the short story publishe...   \n",
              "20  What was the first book released after everyon...   \n",
              "21                 What object is the Blue Carbuncle?   \n",
              "22        What is Sherlock Holmes's most famous line?   \n",
              "23  On what British TV channel is the series Sherl...   \n",
              "24  In The Hound Of The Baskervilles, what village...   \n",
              "\n",
              "                  expected_answer  \\\n",
              "0          Sir Arthur Conan Doyle   \n",
              "1              Professor Moriarty   \n",
              "2     221b Baker Street in London   \n",
              "3                 Dr. John Watson   \n",
              "4                  Mycroft Holmes   \n",
              "5                     Mrs. Hudson   \n",
              "6                      The violin   \n",
              "7            A Scandal In Bohemia   \n",
              "8            Benedict Cumberbatch   \n",
              "9                    Mary Morstan   \n",
              "10    The Baker Street Irregulars   \n",
              "11              Robert Downey Jr.   \n",
              "12                       Jude Law   \n",
              "13             A Study In Scarlet   \n",
              "14                   Enola Holmes   \n",
              "15     St. Bartholomew's hospital   \n",
              "16                     Beekeeping   \n",
              "17           In a Persian slipper   \n",
              "18                  John Openshaw   \n",
              "19              The Final Problem   \n",
              "20  The Hound Of The Baskervilles   \n",
              "21           A priceless gemstone   \n",
              "22  \"Elementary, my dear Watson.\"   \n",
              "23                        BBC One   \n",
              "24                        Grimpen   \n",
              "\n",
              "                                     generated_answer difficulty  \\\n",
              "0                                  Arthur Conan Doyle       Easy   \n",
              "1                                  Professor Moriarty       Easy   \n",
              "2                                  221B Baker Street.       Easy   \n",
              "3                                     Dr. John Watson       Easy   \n",
              "4                                            William.       Easy   \n",
              "5                                         Mrs. Hudson       Easy   \n",
              "6                                          The piano.       Easy   \n",
              "7                   The Adventure of the Dancing Men.     Medium   \n",
              "8                                Benedict Cumberbatch       Easy   \n",
              "9                                    Dr. John Watson.     Medium   \n",
              "10                                           Footmen.     Medium   \n",
              "11                                  Robert Downey Jr.       Easy   \n",
              "12                                       Daniel Craig       Easy   \n",
              "13                     The Hound of the Baskervilles.     Medium   \n",
              "14                 Sherlock Holmes: A Game of Shadows       Easy   \n",
              "15                                   At Baker Street.     Medium   \n",
              "16                      He started collecting stamps.     Medium   \n",
              "17                                       In his pipe.       Hard   \n",
              "18       The client’s name is “The Five Orange Pips.”       Hard   \n",
              "19                      The Hound of the Baskervilles     Medium   \n",
              "20  “The Hound of the Baskervilles” by Arthur Cona...     Medium   \n",
              "21                                        A gemstone.     Medium   \n",
              "22                      “Elementary, my dear Watson.”       Easy   \n",
              "23                                               ITV.       Hard   \n",
              "24                                          Dartmoor.       Hard   \n",
              "\n",
              "    is_correct_keyword  semantic_similarity  is_correct_semantic  \\\n",
              "0                False             0.962577                 True   \n",
              "1                 True             1.000000                 True   \n",
              "2                False             0.901767                 True   \n",
              "3                 True             1.000000                 True   \n",
              "4                False             0.264208                False   \n",
              "5                 True             1.000000                 True   \n",
              "6                False             0.587473                 True   \n",
              "7                False             0.200190                False   \n",
              "8                 True             1.000000                 True   \n",
              "9                False             0.315029                False   \n",
              "10               False             0.190314                False   \n",
              "11                True             1.000000                 True   \n",
              "12               False             0.408639                False   \n",
              "13               False             0.277919                False   \n",
              "14               False             0.403840                False   \n",
              "15               False             0.305989                False   \n",
              "16               False             0.177777                False   \n",
              "17               False             0.303259                False   \n",
              "18               False             0.165419                False   \n",
              "19               False             0.125750                False   \n",
              "20                True             0.794517                 True   \n",
              "21               False             0.836267                 True   \n",
              "22               False             0.993280                 True   \n",
              "23               False             0.626558                 True   \n",
              "24               False             0.168748                False   \n",
              "\n",
              "    is_correct_ai_eval  \n",
              "0                 True  \n",
              "1                 True  \n",
              "2                False  \n",
              "3                 True  \n",
              "4                False  \n",
              "5                 True  \n",
              "6                False  \n",
              "7                False  \n",
              "8                 True  \n",
              "9                False  \n",
              "10               False  \n",
              "11                True  \n",
              "12               False  \n",
              "13               False  \n",
              "14               False  \n",
              "15               False  \n",
              "16               False  \n",
              "17               False  \n",
              "18               False  \n",
              "19               False  \n",
              "20                True  \n",
              "21               False  \n",
              "22                True  \n",
              "23               False  \n",
              "24               False  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display the detailed results DataFrame\n",
        "display(results_df)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyN6KOogCZ4ib/uIUYEv9Vsq",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.12.9)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
