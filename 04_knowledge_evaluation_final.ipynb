{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmassaron/fine-tuning-workshop/blob/main/sherlock_knowledge_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhNrI5idd_vH",
        "outputId": "66594aca-2169-4c70-bd17-0904ec9c0ec1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Sep 24 10:25:00 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.163.01             Driver Version: 550.163.01     CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 3090        Off |   00000000:01:00.0  On |                  N/A |\n",
            "|  0%   34C    P8             12W /  350W |    3663MiB /  24576MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A      2036      G   /usr/lib/xorg/Xorg                             70MiB |\n",
            "|    0   N/A  N/A      2184      G   /usr/bin/gnome-shell                           72MiB |\n",
            "|    0   N/A  N/A      5617      C   .../code/sft-workshop/.venv/bin/python       3506MiB |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check the GPU information\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnjgsKN_esrw"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries for model training and evaluation\n",
        "#%%capture\n",
        "#!pip install -U transformers trl accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbszOixGedSt",
        "outputId": "1b1326fe-82e0-47fd-e5d0-94ae33116084"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using PyTorch version: 2.8.0+cu128\n",
            "Using TRL version: 0.22.2\n",
            "Using bitsandbytes version: 0.47.0\n"
          ]
        }
      ],
      "source": [
        "# Import and print the versions of the installed libraries\n",
        "import torch\n",
        "import trl\n",
        "import bitsandbytes\n",
        "\n",
        "print(f\"Using PyTorch version: {torch.__version__}\")\n",
        "print(f\"Using TRL version: {trl.__version__}\")\n",
        "print(f\"Using bitsandbytes version: {bitsandbytes.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YfeOmO0cfNGh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 09-24 10:25:03 [__init__.py:216] Automatically detected platform cuda.\n"
          ]
        }
      ],
      "source": [
        "# Import various libraries needed for data handling, model loading, and training\n",
        "import os\n",
        "import gc\n",
        "import warnings\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from datasets import Dataset, load_dataset\n",
        "from huggingface_hub import login\n",
        "from peft import LoraConfig\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from trl import GRPOConfig, GRPOTrainer, SFTConfig, SFTTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CrTseGUkffTN"
      },
      "outputs": [],
      "source": [
        "# Define configuration parameters for the model and data\n",
        "class Config:\n",
        "    \"\"\"Configuration parameters\"\"\"\n",
        "\n",
        "    SIZE = \"3-1b\"\n",
        "    # MODEL_NAME = f\"google/gemma-{SIZE}-it\"\n",
        "    MODEL_NAME = \"lmassaron/gemma-3-1b-sherlock-expert\"\n",
        "\n",
        "    max_prompt_length = 352\n",
        "    max_completion_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0_hM-990eqrr"
      },
      "outputs": [],
      "source": [
        "# Initialization script to set up the environment and Hugging Face login\n",
        "def init():\n",
        "    \"\"\"Initialization script\"\"\"\n",
        "    os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"0\"\n",
        "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
        "\n",
        "    # It is recommended to set the HF_TOKEN as an environment variable\n",
        "    token = os.environ.get(\"HF_TOKEN\")\n",
        "    if token:\n",
        "        login(token=token)\n",
        "    else:\n",
        "      try:\n",
        "        from google.colab import userdata\n",
        "        # Retrieve your Hugging Face token from Colab's secrets manager\n",
        "        # The name 'HF_TOKEN' should match the name you used in the secrets tab\n",
        "        hf_token = userdata.get('HF_TOKEN')\n",
        "\n",
        "        # Check if the token was successfully retrieved\n",
        "        if hf_token:\n",
        "            # Log in to Hugging Face using the retrieved token\n",
        "            # The `add_to_git_credential=True` argument is optional and useful if you plan to push models to the Hub\n",
        "            login(token=hf_token, add_to_git_credential=True)\n",
        "            print(\"Hugging Face login successful using Google Colab secrets!\")\n",
        "        else:\n",
        "            print(\"Error: HF_TOKEN not found in Google Colab secrets or is empty.\")\n",
        "            print(\"Please ensure you have created a secret named 'HF_TOKEN' in the 'Secrets' tab (ðŸ”‘) on the left sidebar.\")\n",
        "      except:\n",
        "        print(\"HF_TOKEN not set. You might need to log in manually.\")\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def is_bfloat16_supported():\n",
        "    \"\"\"Checks if the current device supports bfloat16.\"\"\"\n",
        "    return torch.cuda.is_available() and torch.cuda.get_device_capability(0)[0] >= 8\n",
        "\n",
        "\n",
        "def info_device():\n",
        "    \"\"\"Get device for PyTorch\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "    return device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lW6ft5_SfOV5",
        "outputId": "36ada8c2-ec90-47f7-b3b2-6411560311e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Using dtype: torch.bfloat16\n"
          ]
        }
      ],
      "source": [
        "# Initialize the environment, get parameters, device, and data type\n",
        "init()\n",
        "params = Config()\n",
        "device = info_device()\n",
        "dtype = torch.bfloat16 if is_bfloat16_supported() else torch.float16\n",
        "print(f\"Using dtype: {dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1OtC1THhf0VS"
      },
      "outputs": [],
      "source": [
        "# Function to load dataset from Hugging Face Hub\n",
        "def get_data(repo_id, mapping_func=None, split=\"train\"):\n",
        "    \"\"\"Upload HF dataset\"\"\"\n",
        "    data = load_dataset(repo_id, cache_dir=\"/tmp\")[split]\n",
        "    if mapping_func:\n",
        "      data = data.map(mapping_func)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7ty8thGnhB1M"
      },
      "outputs": [],
      "source": [
        "# Load the Sherlock QA dataset\n",
        "data = get_data(repo_id=\"lmassaron/Sherlock_QA_test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19ihvnylhGEE",
        "outputId": "83976fdf-658e-4321-b36f-35ab4c43d4c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Question', 'Answer', 'Difficulty'],\n",
              "    num_rows: 25\n",
              "})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the loaded dataset information\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ag2jIkzshLAK"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f3d6de91153445392814f6c5a773932",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/210 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the tokenizer and model from Hugging Face\n",
        "tokenizer = AutoTokenizer.from_pretrained(params.MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    params.MODEL_NAME,\n",
        "    torch_dtype=dtype,\n",
        "    device_map=device,\n",
        "    use_cache=True\n",
        ")\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhzjOp95hXVG",
        "outputId": "902d01c6-d58c-488c-ad8d-ba937b31fdca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating Samples:   0%|          | 0/25 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:   4%|â–         | 1/25 [00:21<08:34, 21.42s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:   8%|â–Š         | 2/25 [00:52<10:25, 27.18s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:  16%|â–ˆâ–Œ        | 4/25 [00:52<03:33, 10.17s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:  24%|â–ˆâ–ˆâ–       | 6/25 [01:10<02:59,  9.46s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [01:10<01:15,  4.73s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [01:27<01:07,  5.19s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [01:27<00:41,  3.73s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [01:27<00:18,  2.33s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [01:45<00:24,  4.02s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [02:03<00:31,  6.22s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [02:03<00:12,  4.31s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [02:03<00:03,  3.01s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Evaluating Samples: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [02:03<00:00,  4.95s/it]\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the dataset and store results\n",
        "temperature = 0\n",
        "results_list = []\n",
        "instructions = \"\\nBriefly, just give the straight answer to the question.\"\n",
        "\n",
        "# It's good practice to set the pad_token if it's not already set.\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "for row in tqdm(data, desc=\"Evaluating Samples\"):\n",
        "  question = row['Question']\n",
        "  answer = row['Answer']\n",
        "  difficulty = row['Difficulty']\n",
        "\n",
        "  # Tokenize the input and get both input_ids and attention_mask\n",
        "  inputs = tokenizer.apply_chat_template(\n",
        "            [{\"role\": \"user\", \"content\": question + instructions}],\n",
        "            tokenize=True,\n",
        "            add_generation_prompt=True,  # Crucial for telling the model it's its turn to speak\n",
        "            return_tensors=\"pt\",\n",
        "            return_dict=True  # Ensure the output is a dictionary\n",
        "        ).to(device)\n",
        "\n",
        "  # Prepare arguments for the generate function\n",
        "  generation_kwargs = {\n",
        "      \"pad_token_id\": tokenizer.eos_token_id,\n",
        "      \"max_new_tokens\": params.max_completion_length,\n",
        "      \"do_sample\": temperature > 0\n",
        "  }\n",
        "\n",
        "  # Only add temperature to kwargs if sampling is enabled\n",
        "  if generation_kwargs[\"do_sample\"]:\n",
        "      generation_kwargs[\"temperature\"] = temperature\n",
        "\n",
        "  # Generate a completion from the model, passing the attention_mask\n",
        "  outputs = model.generate(\n",
        "      inputs.input_ids, # Pass input_ids explicitly\n",
        "      attention_mask=inputs.attention_mask, # Pass the attention mask\n",
        "      **generation_kwargs\n",
        "      )\n",
        "\n",
        "  generated_token_ids = outputs[0, inputs.input_ids.shape[-1] :]\n",
        "  generated_text = tokenizer.decode(\n",
        "      generated_token_ids,\n",
        "      skip_special_tokens=True,\n",
        "  ).strip()\n",
        "\n",
        "  results_list.append({\n",
        "      'question': question,\n",
        "      'expected_answer': answer,\n",
        "      'generated_answer': generated_text,\n",
        "      'difficulty': difficulty\n",
        "  })\n",
        "\n",
        "results_df = pd.DataFrame(results_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WkXFPkxWRztL"
      },
      "outputs": [],
      "source": [
        "# Delete the model and tokenizer to free up GPU memory\n",
        "del [model, tokenizer]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MypZobdjqjYg"
      },
      "outputs": [],
      "source": [
        "# Evaluate correctness based on keyword matching\n",
        "def evaluate_keyword(row):\n",
        "    return row['expected_answer'].lower() in row['generated_answer'].lower()\n",
        "\n",
        "results_df['is_correct_keyword'] = results_df.apply(evaluate_keyword, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-b62iLlS1cJb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16767240751b433da0ebe02590623d8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8fd77c709a9746ed9a67a9b518a72570",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4fe2b02e7a44fe184aad6d9243b7b36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56fbfe450c0a4f9191cd65992ddeb37f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec62e2ca60c84056897de6f683c3dc99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a68f0661cc3477ab665885602aa79aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58136c4a47004bba96e7976cbef820c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc2294bf27c24ae09871b71526b47f87",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "165f9ae334f344c68bb8a061e5cd03a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6b19a1e8697440699c0f102838fc531",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fd9db48a9d34ebe9affddd7ef2a7762",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Evaluate correctness based on semantic similarity using Sentence-BERT\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Load the Sentence-BERT model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Encode the expected and generated answers into embeddings\n",
        "expected_embeddings = model.encode(results_df['expected_answer'].tolist(), convert_to_tensor=True)\n",
        "generated_embeddings = model.encode(results_df['generated_answer'].tolist(), convert_to_tensor=True)\n",
        "\n",
        "# Calculate cosine similarity between embeddings\n",
        "cosine_scores = util.cos_sim(expected_embeddings, generated_embeddings)\n",
        "cosine_scores = np.array(cosine_scores.cpu())\n",
        "\n",
        "# Store the semantic similarity scores\n",
        "results_df['semantic_similarity'] = [cosine_scores[i][i] for i in range(len(cosine_scores))]\n",
        "\n",
        "# Determine correctness based on a similarity threshold\n",
        "similarity_threshold = 0.5\n",
        "results_df['is_correct_semantic'] = results_df['semantic_similarity'] >= similarity_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "EMCEuo_TR352"
      },
      "outputs": [],
      "source": [
        "# Delete the Sentence-BERT model to free up memory\n",
        "del [model]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "B4D_3Auh7osc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19164524a604413692751534c5de0bfe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a2e8d24bc5c45f7a5aa0526621cef0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the evaluation model and tokenizer (AI Judge)\n",
        "evaluation_model = \"meta-llama/Llama-3.2-3B-Instruct\" # \"alpindale/Llama-3.2-3B-Instruct\"\n",
        "eval_tokenizer = AutoTokenizer.from_pretrained(evaluation_model)\n",
        "eval_model = AutoModelForCausalLM.from_pretrained(\n",
        "    evaluation_model,\n",
        "    torch_dtype=dtype,\n",
        "    device_map=device,\n",
        "    use_cache=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UmScYdFOvz0",
        "outputId": "a9cb3d83-3e14-4279-8ee0-15e1bb221521"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:03<00:00,  8.18it/s]\n"
          ]
        }
      ],
      "source": [
        "# Function to generate the prompt for the AI judge\n",
        "def evaluation_prompt(question, expected_answer, generated_answer):\n",
        "  prompt = f\"\"\"You are an impartial evaluator.\n",
        "Your task is to determine if the \"Generated Answer\", even if too verbose, correctly answers the \"Question\".\n",
        "The \"Expected Answer\" is provided as a reference for the correct information.\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Expected Answer:\n",
        "{expected_answer}\n",
        "\n",
        "Generated Answer:\n",
        "{generated_answer}\n",
        "\n",
        "Is the \"Generated Answer\" correct? Please answer with \"Yes\" or \"No\".\n",
        "\"\"\"\n",
        "  return prompt\n",
        "\n",
        "# Evaluate generated answers using the AI judge\n",
        "ai_judge = []\n",
        "\n",
        "for i in tqdm(range(len(results_df))):\n",
        "  question = results_df.iloc[i]['question']\n",
        "  expected_answer = results_df.iloc[i]['expected_answer']\n",
        "  generated_answer = results_df.iloc[i]['generated_answer']\n",
        "  prompt = evaluation_prompt(question, expected_answer, generated_answer)\n",
        "\n",
        "  inputs = eval_tokenizer.apply_chat_template(\n",
        "            [{\"role\": \"user\", \"content\": prompt}],\n",
        "            tokenize=True,\n",
        "            add_generation_prompt=True,\n",
        "            return_tensors=\"pt\",\n",
        "        ).to(device)\n",
        "\n",
        "  # Generate a response from the AI judge\n",
        "  outputs = eval_model.generate(\n",
        "      inputs,\n",
        "      pad_token_id=eval_tokenizer.eos_token_id,\n",
        "      max_new_tokens=100,\n",
        "      temperature=0.1,\n",
        "      do_sample=True,\n",
        "  )\n",
        "\n",
        "  generated_token_ids = outputs[0, inputs.shape[-1] :]\n",
        "  generated_text = eval_tokenizer.decode(\n",
        "      generated_token_ids,\n",
        "      skip_special_tokens=True,\n",
        "  ).strip()\n",
        "\n",
        "  # Determine correctness based on the AI judge's response\n",
        "  if \"yes\" in generated_text.lower():\n",
        "    ai_judge.append(True)\n",
        "  else:\n",
        "    ai_judge.append(False)\n",
        "\n",
        "results_df[\"is_correct_ai_eval\"] = ai_judge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aff7ce6",
        "outputId": "d676269a-4847-47b5-ca2f-80dd0f4c9553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Keyword Matching Accuracy: 0.24\n",
            "Overall Semantic Similarity Accuracy (threshold=0.5): 0.44\n",
            "Overall AI Judge Accuracy: 0.36\n"
          ]
        }
      ],
      "source": [
        "# Calculate overall correctness metrics for each evaluation method\n",
        "overall_keyword_accuracy = results_df['is_correct_keyword'].mean()\n",
        "overall_semantic_accuracy = results_df['is_correct_semantic'].mean()\n",
        "overall_ai_judge_accuracy = results_df['is_correct_ai_eval'].mean()\n",
        "\n",
        "print(f\"Overall Keyword Matching Accuracy: {overall_keyword_accuracy:.2f}\")\n",
        "print(f\"Overall Semantic Similarity Accuracy (threshold=0.5): {overall_semantic_accuracy:.2f}\")\n",
        "print(f\"Overall AI Judge Accuracy: {overall_ai_judge_accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "bb165b21",
        "outputId": "543b9bc6-e966-4752-f51a-2ee416db1d42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Keyword Matching Accuracy by Difficulty:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>difficulty</th>\n",
              "      <th>is_correct_keyword</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Easy</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hard</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Medium</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  difficulty  is_correct_keyword\n",
              "0       Easy            0.250000\n",
              "1       Hard            0.000000\n",
              "2     Medium            0.333333"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Semantic Similarity Accuracy by Difficulty (threshold=0.5):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>difficulty</th>\n",
              "      <th>is_correct_semantic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Easy</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hard</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Medium</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  difficulty  is_correct_semantic\n",
              "0       Easy             0.500000\n",
              "1       Hard             0.250000\n",
              "2     Medium             0.444444"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "AI Judge Accuracy by Difficulty:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>difficulty</th>\n",
              "      <th>is_correct_ai_eval</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Easy</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hard</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Medium</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  difficulty  is_correct_ai_eval\n",
              "0       Easy            0.500000\n",
              "1       Hard            0.000000\n",
              "2     Medium            0.333333"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Analyze correctness by difficulty for each evaluation method\n",
        "difficulty_analysis_keyword = results_df.groupby('difficulty')['is_correct_keyword'].mean().reset_index()\n",
        "difficulty_analysis_semantic = results_df.groupby('difficulty')['is_correct_semantic'].mean().reset_index()\n",
        "difficulty_analysis_ai_judge = results_df.groupby('difficulty')['is_correct_ai_eval'].mean().reset_index()\n",
        "\n",
        "print(\"\\nKeyword Matching Accuracy by Difficulty:\")\n",
        "display(difficulty_analysis_keyword)\n",
        "\n",
        "print(\"\\nSemantic Similarity Accuracy by Difficulty (threshold=0.5):\")\n",
        "display(difficulty_analysis_semantic)\n",
        "\n",
        "print(\"\\nAI Judge Accuracy by Difficulty:\")\n",
        "display(difficulty_analysis_ai_judge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d8af88b9",
        "outputId": "314c1dc7-e013-40e4-a191-5cf2a2a04422"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>expected_answer</th>\n",
              "      <th>generated_answer</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>is_correct_keyword</th>\n",
              "      <th>semantic_similarity</th>\n",
              "      <th>is_correct_semantic</th>\n",
              "      <th>is_correct_ai_eval</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Who created the character of Sherlock Holmes?</td>\n",
              "      <td>Sir Arthur Conan Doyle</td>\n",
              "      <td>Sir Arthur Conan Doyle</td>\n",
              "      <td>Easy</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the name of Sherlock Holmes's enemy?</td>\n",
              "      <td>Professor Moriarty</td>\n",
              "      <td>Jack the Ripper</td>\n",
              "      <td>Easy</td>\n",
              "      <td>False</td>\n",
              "      <td>0.283280</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Where does Sherlock Holmes live?</td>\n",
              "      <td>221b Baker Street in London</td>\n",
              "      <td>221B Baker Street</td>\n",
              "      <td>Easy</td>\n",
              "      <td>False</td>\n",
              "      <td>0.912416</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Who is Sherlock Holmes's best friend?</td>\n",
              "      <td>Dr. John Watson</td>\n",
              "      <td>Mycroft Holmes</td>\n",
              "      <td>Easy</td>\n",
              "      <td>False</td>\n",
              "      <td>0.492548</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the name of Sherlock's older brother?</td>\n",
              "      <td>Mycroft Holmes</td>\n",
              "      <td>Mycroft</td>\n",
              "      <td>Easy</td>\n",
              "      <td>False</td>\n",
              "      <td>0.842383</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Who is the landlady of 221b Baker Street?</td>\n",
              "      <td>Mrs. Hudson</td>\n",
              "      <td>Mrs. Hudson</td>\n",
              "      <td>Easy</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What musical instrument does Sherlock Holmes l...</td>\n",
              "      <td>The violin</td>\n",
              "      <td>A violin</td>\n",
              "      <td>Easy</td>\n",
              "      <td>False</td>\n",
              "      <td>0.939922</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>In which Sherlock Holmes short story do we mee...</td>\n",
              "      <td>A Scandal In Bohemia</td>\n",
              "      <td>A Scandal in Bohemia</td>\n",
              "      <td>Medium</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Which actor plays Sherlock Holmes in the TV se...</td>\n",
              "      <td>Benedict Cumberbatch</td>\n",
              "      <td>Benedict Cumberbatch</td>\n",
              "      <td>Easy</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Who did Dr. Watson marry?</td>\n",
              "      <td>Mary Morstan</td>\n",
              "      <td>Mary Watson</td>\n",
              "      <td>Medium</td>\n",
              "      <td>False</td>\n",
              "      <td>0.618045</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What are the street boys called who run errand...</td>\n",
              "      <td>The Baker Street Irregulars</td>\n",
              "      <td>The street boys</td>\n",
              "      <td>Medium</td>\n",
              "      <td>False</td>\n",
              "      <td>0.418026</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Who stars as Sherlock Holmes in the 2009 film ...</td>\n",
              "      <td>Robert Downey Jr.</td>\n",
              "      <td>Not mentioned</td>\n",
              "      <td>Easy</td>\n",
              "      <td>False</td>\n",
              "      <td>0.138356</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Who stars as Watson in the 2009 film Sherlock ...</td>\n",
              "      <td>Jude Law</td>\n",
              "      <td>Not mentioned</td>\n",
              "      <td>Easy</td>\n",
              "      <td>False</td>\n",
              "      <td>0.159629</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What was the first Sherlock Holmes story titled?</td>\n",
              "      <td>A Study In Scarlet</td>\n",
              "      <td>The Adventure of the Resident Patient</td>\n",
              "      <td>Medium</td>\n",
              "      <td>False</td>\n",
              "      <td>0.230198</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Which 2020 film features the teenage sister of...</td>\n",
              "      <td>Enola Holmes</td>\n",
              "      <td>The Last King</td>\n",
              "      <td>Easy</td>\n",
              "      <td>False</td>\n",
              "      <td>0.165231</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Where did Sherlock and Watson first meet?</td>\n",
              "      <td>St. Bartholomew's hospital</td>\n",
              "      <td>A pub</td>\n",
              "      <td>Medium</td>\n",
              "      <td>False</td>\n",
              "      <td>0.307756</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>When Sherlock Holmes retired, what hobby did h...</td>\n",
              "      <td>Beekeeping</td>\n",
              "      <td>Collecting porcelain</td>\n",
              "      <td>Medium</td>\n",
              "      <td>False</td>\n",
              "      <td>0.247680</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Where does Sherlock Holmes keep his tobacco?</td>\n",
              "      <td>In a Persian slipper</td>\n",
              "      <td>In the coal-scuttle</td>\n",
              "      <td>Hard</td>\n",
              "      <td>False</td>\n",
              "      <td>0.268886</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>What is the client's name in the short story \"...</td>\n",
              "      <td>John Openshaw</td>\n",
              "      <td>Not mentioned</td>\n",
              "      <td>Hard</td>\n",
              "      <td>False</td>\n",
              "      <td>0.141029</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>What was the title of the short story publishe...</td>\n",
              "      <td>The Final Problem</td>\n",
              "      <td>The Final Problem</td>\n",
              "      <td>Medium</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>What was the first book released after everyon...</td>\n",
              "      <td>The Hound Of The Baskervilles</td>\n",
              "      <td>The Hound of the Baskervilles</td>\n",
              "      <td>Medium</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>What object is the Blue Carbuncle?</td>\n",
              "      <td>A priceless gemstone</td>\n",
              "      <td>The Blue Carbuncle is a small square square sh...</td>\n",
              "      <td>Medium</td>\n",
              "      <td>False</td>\n",
              "      <td>0.089622</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>What is Sherlock Holmes's most famous line?</td>\n",
              "      <td>\"Elementary, my dear Watson.\"</td>\n",
              "      <td>'The man who is born to be a detective is as r...</td>\n",
              "      <td>Easy</td>\n",
              "      <td>False</td>\n",
              "      <td>0.280917</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>On what British TV channel is the series Sherl...</td>\n",
              "      <td>BBC One</td>\n",
              "      <td>BBC Two</td>\n",
              "      <td>Hard</td>\n",
              "      <td>False</td>\n",
              "      <td>0.866817</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>In The Hound Of The Baskervilles, what village...</td>\n",
              "      <td>Grimpen</td>\n",
              "      <td>No specific village mentioned</td>\n",
              "      <td>Hard</td>\n",
              "      <td>False</td>\n",
              "      <td>0.164528</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question  \\\n",
              "0       Who created the character of Sherlock Holmes?   \n",
              "1        What is the name of Sherlock Holmes's enemy?   \n",
              "2                    Where does Sherlock Holmes live?   \n",
              "3               Who is Sherlock Holmes's best friend?   \n",
              "4       What is the name of Sherlock's older brother?   \n",
              "5           Who is the landlady of 221b Baker Street?   \n",
              "6   What musical instrument does Sherlock Holmes l...   \n",
              "7   In which Sherlock Holmes short story do we mee...   \n",
              "8   Which actor plays Sherlock Holmes in the TV se...   \n",
              "9                           Who did Dr. Watson marry?   \n",
              "10  What are the street boys called who run errand...   \n",
              "11  Who stars as Sherlock Holmes in the 2009 film ...   \n",
              "12  Who stars as Watson in the 2009 film Sherlock ...   \n",
              "13   What was the first Sherlock Holmes story titled?   \n",
              "14  Which 2020 film features the teenage sister of...   \n",
              "15          Where did Sherlock and Watson first meet?   \n",
              "16  When Sherlock Holmes retired, what hobby did h...   \n",
              "17       Where does Sherlock Holmes keep his tobacco?   \n",
              "18  What is the client's name in the short story \"...   \n",
              "19  What was the title of the short story publishe...   \n",
              "20  What was the first book released after everyon...   \n",
              "21                 What object is the Blue Carbuncle?   \n",
              "22        What is Sherlock Holmes's most famous line?   \n",
              "23  On what British TV channel is the series Sherl...   \n",
              "24  In The Hound Of The Baskervilles, what village...   \n",
              "\n",
              "                  expected_answer  \\\n",
              "0          Sir Arthur Conan Doyle   \n",
              "1              Professor Moriarty   \n",
              "2     221b Baker Street in London   \n",
              "3                 Dr. John Watson   \n",
              "4                  Mycroft Holmes   \n",
              "5                     Mrs. Hudson   \n",
              "6                      The violin   \n",
              "7            A Scandal In Bohemia   \n",
              "8            Benedict Cumberbatch   \n",
              "9                    Mary Morstan   \n",
              "10    The Baker Street Irregulars   \n",
              "11              Robert Downey Jr.   \n",
              "12                       Jude Law   \n",
              "13             A Study In Scarlet   \n",
              "14                   Enola Holmes   \n",
              "15     St. Bartholomew's hospital   \n",
              "16                     Beekeeping   \n",
              "17           In a Persian slipper   \n",
              "18                  John Openshaw   \n",
              "19              The Final Problem   \n",
              "20  The Hound Of The Baskervilles   \n",
              "21           A priceless gemstone   \n",
              "22  \"Elementary, my dear Watson.\"   \n",
              "23                        BBC One   \n",
              "24                        Grimpen   \n",
              "\n",
              "                                     generated_answer difficulty  \\\n",
              "0                              Sir Arthur Conan Doyle       Easy   \n",
              "1                                     Jack the Ripper       Easy   \n",
              "2                                   221B Baker Street       Easy   \n",
              "3                                      Mycroft Holmes       Easy   \n",
              "4                                             Mycroft       Easy   \n",
              "5                                         Mrs. Hudson       Easy   \n",
              "6                                            A violin       Easy   \n",
              "7                                A Scandal in Bohemia     Medium   \n",
              "8                                Benedict Cumberbatch       Easy   \n",
              "9                                         Mary Watson     Medium   \n",
              "10                                    The street boys     Medium   \n",
              "11                                      Not mentioned       Easy   \n",
              "12                                      Not mentioned       Easy   \n",
              "13              The Adventure of the Resident Patient     Medium   \n",
              "14                                      The Last King       Easy   \n",
              "15                                              A pub     Medium   \n",
              "16                               Collecting porcelain     Medium   \n",
              "17                                In the coal-scuttle       Hard   \n",
              "18                                      Not mentioned       Hard   \n",
              "19                                  The Final Problem     Medium   \n",
              "20                      The Hound of the Baskervilles     Medium   \n",
              "21  The Blue Carbuncle is a small square square sh...     Medium   \n",
              "22  'The man who is born to be a detective is as r...       Easy   \n",
              "23                                            BBC Two       Hard   \n",
              "24                      No specific village mentioned       Hard   \n",
              "\n",
              "    is_correct_keyword  semantic_similarity  is_correct_semantic  \\\n",
              "0                 True             1.000000                 True   \n",
              "1                False             0.283280                False   \n",
              "2                False             0.912416                 True   \n",
              "3                False             0.492548                False   \n",
              "4                False             0.842383                 True   \n",
              "5                 True             1.000000                 True   \n",
              "6                False             0.939922                 True   \n",
              "7                 True             1.000000                 True   \n",
              "8                 True             1.000000                 True   \n",
              "9                False             0.618045                 True   \n",
              "10               False             0.418026                False   \n",
              "11               False             0.138356                False   \n",
              "12               False             0.159629                False   \n",
              "13               False             0.230198                False   \n",
              "14               False             0.165231                False   \n",
              "15               False             0.307756                False   \n",
              "16               False             0.247680                False   \n",
              "17               False             0.268886                False   \n",
              "18               False             0.141029                False   \n",
              "19                True             1.000000                 True   \n",
              "20                True             1.000000                 True   \n",
              "21               False             0.089622                False   \n",
              "22               False             0.280917                False   \n",
              "23               False             0.866817                 True   \n",
              "24               False             0.164528                False   \n",
              "\n",
              "    is_correct_ai_eval  \n",
              "0                 True  \n",
              "1                False  \n",
              "2                 True  \n",
              "3                False  \n",
              "4                 True  \n",
              "5                 True  \n",
              "6                 True  \n",
              "7                 True  \n",
              "8                 True  \n",
              "9                False  \n",
              "10               False  \n",
              "11               False  \n",
              "12               False  \n",
              "13               False  \n",
              "14               False  \n",
              "15               False  \n",
              "16               False  \n",
              "17               False  \n",
              "18               False  \n",
              "19                True  \n",
              "20                True  \n",
              "21               False  \n",
              "22               False  \n",
              "23               False  \n",
              "24               False  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display the detailed results DataFrame\n",
        "display(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tenacity import retry, stop_after_attempt, wait_fixed\n",
        "\n",
        "# Function to load dataset from Hugging Face Hub with retries\n",
        "@retry(stop=stop_after_attempt(5), wait=wait_fixed(10)) # Retry up to 5 times with 10 seconds delay\n",
        "def get_data(repo_id, mapping_func=None, split=\"train\"):\n",
        "    \"\"\"Upload HF dataset with retries\"\"\"\n",
        "    print(f\"Attempting to load dataset {repo_id}, split {split}...\")\n",
        "    data = load_dataset(repo_id, cache_dir=\"/tmp\")[split]\n",
        "    if mapping_func:\n",
        "      data = data.map(mapping_func)\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "T5XnCogZS6Cn",
        "outputId": "0f375765-c8b4-401e-d770-044e0b2891ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "question                     What is Sherlock Holmes's most famous line?\n",
              "expected_answer                            \"Elementary, my dear Watson.\"\n",
              "generated_answer       'The man who is born to be a detective is as r...\n",
              "difficulty                                                          Easy\n",
              "is_correct_keyword                                                 False\n",
              "semantic_similarity                                             0.280917\n",
              "is_correct_semantic                                                False\n",
              "is_correct_ai_eval                                                 False\n",
              "Name: 22, dtype: object"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = get_data(repo_id=\"lmassaron/Sherlock_QA\")\n",
        "test_data = get_data(repo_id=\"lmassaron/Sherlock_QA_test\")\n",
        "\n",
        "for k, item in enumerate(test_data):\n",
        "    answer = item[\"Answer\"].lower()\n",
        "    counter = 0\n",
        "    for messages in data:\n",
        "        for content in messages[\"messages\"]:\n",
        "            if content[\"role\"] == \"assistant\":\n",
        "                if answer in content[\"content\"].lower():\n",
        "                    counter += 1\n",
        "    print(\n",
        "        f\"The answer to the question {k} ({item[\"Question\"][:50]}) appears {counter} times in the training data\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyN6KOogCZ4ib/uIUYEv9Vsq",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.12.9)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
