{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmassaron/fine-tuning-workshop/blob/main/03_fine_tuning_QA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DdB5YJlNXXq",
        "outputId": "b6d4a199-dd09-4839-91fd-0dc2fc88add9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Sep 25 13:45:37 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.163.01             Driver Version: 550.163.01     CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 3090        Off |   00000000:01:00.0  On |                  N/A |\n",
            "| 30%   39C    P5             31W /  350W |     482MiB /  24576MiB |     41%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A      2018      G   /usr/lib/xorg/Xorg                            218MiB |\n",
            "|    0   N/A  N/A      2164      G   /usr/bin/gnome-shell                           84MiB |\n",
            "|    0   N/A  N/A      4735      G   /usr/share/code/code                          111MiB |\n",
            "|    0   N/A  N/A     31148      G   ...irefox/6836/usr/lib/firefox/firefox         13MiB |\n",
            "|    0   N/A  N/A     32431      G   /snap/slack/215/usr/lib/slack/slack            32MiB |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check the GPU information\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-Gxk-fyRIzO"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries for model training and evaluation\n",
        "%%capture\n",
        "!pip install -U transformers trl peft accelerate bitsandbytes\n",
        "!pip install tenacity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmVggCLHRIwm",
        "outputId": "a13e6652-c51c-436b-981e-ef310fc0902d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using PyTorch version: 2.8.0+cu128\n",
            "Using TRL version: 0.22.2\n",
            "Using peft version: 0.17.1\n",
            "Using bitsandbytes version: 0.47.0\n"
          ]
        }
      ],
      "source": [
        "# Import and print the versions of the installed libraries\n",
        "import torch\n",
        "import trl\n",
        "import peft\n",
        "import bitsandbytes\n",
        "\n",
        "print(f\"Using PyTorch version: {torch.__version__}\")\n",
        "print(f\"Using TRL version: {trl.__version__}\")\n",
        "print(f\"Using peft version: {peft.__version__}\")\n",
        "print(f\"Using bitsandbytes version: {bitsandbytes.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XGjIbALROk6",
        "outputId": "bb707813-ccf8-46bb-81ac-269dcf15c12b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 09-25 13:46:01 [__init__.py:216] Automatically detected platform cuda.\n"
          ]
        }
      ],
      "source": [
        "# Import various libraries needed for data handling, model loading, and training\n",
        "import os\n",
        "import gc\n",
        "import warnings\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import subprocess\n",
        "import sys\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import Dataset, load_dataset\n",
        "from huggingface_hub import login\n",
        "from peft import LoraConfig\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers import set_seed\n",
        "from trl import SFTConfig, SFTTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qqSm9JPqM5C"
      },
      "outputs": [],
      "source": [
        "DEMO = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqjLdOThRIte"
      },
      "outputs": [],
      "source": [
        "# Define configuration parameters for the model and data\n",
        "class Config:\n",
        "    \"\"\"Configuration parameters\"\"\"\n",
        "\n",
        "    SIZE = \"3-1b\"\n",
        "    MODEL_NAME = f\"google/gemma-{SIZE}-it\"\n",
        "    OUTPUT_MODEL = f\"gemma-{SIZE}-sherlock-expert\"\n",
        "\n",
        "    max_seq_length = 2048\n",
        "    seed = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ar0-cOqPRIlN"
      },
      "outputs": [],
      "source": [
        "# Initialization script to set up the environment and Hugging Face login\n",
        "def init():\n",
        "    \"\"\"Initialization script\"\"\"\n",
        "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "    # It is recommended to set the HF_TOKEN as an environment variable\n",
        "    token = os.environ.get(\"HF_TOKEN\")\n",
        "    if token:\n",
        "        login(token=token)\n",
        "    else:\n",
        "      try:\n",
        "        from google.colab import userdata\n",
        "        # Retrieve your Hugging Face token from Colab's secrets manager\n",
        "        # The name 'HF_TOKEN' should match the name you used in the secrets tab\n",
        "        hf_token = userdata.get('HF_TOKEN')\n",
        "\n",
        "        # Check if the token was successfully retrieved\n",
        "        if hf_token:\n",
        "            # Log in to Hugging Face using the retrieved token\n",
        "            # The `add_to_git_credential=True` argument is optional and useful if you plan to push models to the Hub\n",
        "            login(token=hf_token, add_to_git_credential=True)\n",
        "            print(\"Hugging Face login successful using Google Colab secrets!\")\n",
        "        else:\n",
        "            print(\"Error: HF_TOKEN not found in Google Colab secrets or is empty.\")\n",
        "            print(\"Please ensure you have created a secret named 'HF_TOKEN' in the 'Secrets' tab (ðŸ”‘) on the left sidebar.\")\n",
        "      except:\n",
        "        print(\"HF_TOKEN not set. You might need to log in manually.\")\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def is_bfloat16_supported():\n",
        "    \"\"\"Checks if the current device supports bfloat16.\"\"\"\n",
        "    return torch.cuda.is_available() and torch.cuda.get_device_capability(0)[0] >= 8\n",
        "\n",
        "\n",
        "def info_device():\n",
        "    \"\"\"Get device for PyTorch\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "    return device\n",
        "\n",
        "def cleanup(objects=None):\n",
        "    \"\"\"Cleans the memory\"\"\"\n",
        "    if objects is not None:\n",
        "        for obj in objects:\n",
        "            del obj\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "def set_deterministic(seed):\n",
        "  \"\"\"Sets all seeds and CUDA settings for deterministic results.\"\"\"\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU. [2, 3]\n",
        "  set_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`install_flash_attn_conditionally` is a **smart installer** for the `flash-attn` library. Its main purpose is to **check your GPU's hardware and automatically install the correct, compatible version of the library**, or safely skip the installation if your GPU is not supported.\n",
        "\n",
        "It works in three main steps:\n",
        "\n",
        "1.  **Check for a GPU:** It first verifies that you have a CUDA-enabled NVIDIA GPU. If not, it does nothing.\n",
        "2.  **Identify the GPU Architecture:** It then checks the GPU's \"Compute Capability,\" which is like a version number that identifies its architecture (e.g., Turing, Ampere, Hopper).\n",
        "3.  **Install the Correct Version:**\n",
        "    *   For **modern GPUs** (Ampere or newer, capability >= 8.0), it installs the latest and fastest version of `flash-attn`.\n",
        "    *   For **older Turing GPUs** (capability == 7.5), it installs a specific, older version of `flash-attn` that is compatible with that hardware.\n",
        "    *   If the GPU is **not supported**, it prints a message and safely skips the installation to prevent errors.\n",
        "\n",
        "This is necessary because `flash-attn` is a low-level library that relies on specific hardware features, so you need the right version for your specific GPU.\n"
      ],
      "metadata": {
        "id": "lvSxCtojJPAw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FlashAttention is a highly optimized algorithm that completely re-imagines how the \"attention\" mechanism works inside a Transformer model.**\n",
        "\n",
        "The standard attention mechanism is the biggest bottleneck in LLMsâ€”it's slow and uses a massive amount of GPU memory because it has to constantly read and write a huge intermediate matrix to the GPU's main memory.\n",
        "\n",
        "FlashAttention's key innovation is that it's \"IO-aware.\" It cleverly reorganizes the math and uses the GPU's super-fast on-chip memory (SRAM) to perform the calculations in small chunks, **avoiding those slow, memory-intensive read/write operations.** The result is the same, but the process is dramatically faster and more memory-efficient.\n",
        "\n",
        "The speed and memory savings from FlashAttention provide two game-changing benefits during the fine-tuning process:\n",
        "\n",
        "1.  **Faster Training:** Because each training step is faster, your entire fine-tuning job can be completed **2-4 times faster**. This saves a huge amount of time and money on GPU compute costs.\n",
        "\n",
        "2.  **Enables Longer Context:** This is its most powerful advantage. The memory usage of standard attention grows quadratically with the length of the text, making it nearly impossible to fine-tune on long documents. **FlashAttention's memory usage is linear**, meaning you can fine-tune your model on much longer context windows (e.g., 8k, 16k, or more) without running out of memory. This is crucial for building models that can understand long documents, summarize books, or handle extended conversations."
      ],
      "metadata": {
        "id": "mVWt-OGtKKFI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJQUgDsNTeqr"
      },
      "outputs": [],
      "source": [
        "def install_flash_attn_conditionally():\n",
        "    \"\"\"\n",
        "    Checks the GPU's compute capability and installs the appropriate version of flash-attn.\n",
        "    \"\"\"\n",
        "    if not torch.cuda.is_available():\n",
        "        print(\"No CUDA-enabled GPU found. Skipping flash-attn installation.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Get the compute capability of the first available GPU\n",
        "        major, minor = torch.cuda.get_device_capability(0)\n",
        "        compute_capability = float(f\"{major}.{minor}\")\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        print(f\"Found GPU: {gpu_name} with Compute Capability: {compute_capability}\")\n",
        "\n",
        "        # Check for Ampere, Ada, Hopper, or newer architectures (for FlashAttention 2)\n",
        "        if compute_capability >= 8.0:\n",
        "            # Ampere, Ada, and Hopper architectures support bfloat16 and are ideal for FlashAttention 2\n",
        "            is_bf16_supported = torch.cuda.is_bf16_supported()\n",
        "            if is_bf16_supported:\n",
        "                print(\"GPU supports BF16 and is compatible with FlashAttention 2.\")\n",
        "                print(\"Proceeding with installation of the latest 'flash-attn'...\")\n",
        "                # Install the latest version of flash-attn\n",
        "                install_package(\"flash-attn\", \"-q\", \"--no-build-isolation\") # Pass arguments correctly\n",
        "                return True\n",
        "            else:\n",
        "                 print(\"GPU architecture is compatible, but BF16 is not supported. Skipping installation.\")\n",
        "                 return False\n",
        "        # Check for Turing architecture (for original FlashAttention)\n",
        "        elif compute_capability == 7.5:\n",
        "            print(\"Turing architecture GPU detected. Compatible with original FlashAttention (v1.x).\")\n",
        "            print(\"Proceeding with installation of 'flash-attn==1.0.9'...\")\n",
        "            # Install a specific version of flash-attn compatible with Turing\n",
        "            install_package(\"flash-attn==1.0.9\", \"-q\", \"--no-build-isolation\") # Pass arguments correctly\n",
        "            return True\n",
        "\n",
        "        else:\n",
        "            print(f\"GPU with compute capability {compute_capability} is not supported by flash-attn. Skipping installation.\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during GPU check or installation: {e}\")\n",
        "        return False\n",
        "\n",
        "def install_package(package_name, *pip_args):\n",
        "    \"\"\"\n",
        "    A helper function to install a pip package using subprocess.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        command = [sys.executable, \"-m\", \"pip\", \"install\", package_name]\n",
        "        command.extend(pip_args) # Extend with individual arguments\n",
        "        subprocess.check_call(command)\n",
        "        print(f\"Successfully installed {package_name}.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error installing {package_name}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3_Z-8ANQchp",
        "outputId": "d00ab44d-744d-4195-e9b2-a50d5808189d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Using dtype: torch.bfloat16\n",
            "Found GPU: NVIDIA GeForce RTX 3090 with Compute Capability: 8.6\n",
            "GPU supports BF16 and is compatible with FlashAttention 2.\n",
            "Proceeding with installation of the latest 'flash-attn'...\n",
            "Successfully installed flash-attn.\n"
          ]
        }
      ],
      "source": [
        "# Initialize the environment, get parameters, device, and data type\n",
        "init()\n",
        "params = Config()\n",
        "device = info_device()\n",
        "dtype = torch.bfloat16 if is_bfloat16_supported() else torch.float16\n",
        "print(f\"Using dtype: {dtype}\")\n",
        "is_flash_attn_available = install_flash_attn_conditionally()\n",
        "set_deterministic(params.seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsqZ-Jr3R12y"
      },
      "outputs": [],
      "source": [
        "from tenacity import retry, stop_after_attempt, wait_fixed\n",
        "\n",
        "# Function to load dataset from Hugging Face Hub with retries\n",
        "@retry(stop=stop_after_attempt(5), wait=wait_fixed(10)) # Retry up to 5 times with 10 seconds delay\n",
        "def get_data(repo_id, mapping_func=None, split=\"train\"):\n",
        "    \"\"\"Upload HF dataset with retries\"\"\"\n",
        "    print(f\"Attempting to load dataset {repo_id}, split {split}...\")\n",
        "    data = load_dataset(repo_id, cache_dir=\"/tmp\")[split]\n",
        "    if mapping_func:\n",
        "      data = data.map(mapping_func)\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2oTLcc9R2iY",
        "outputId": "42e7ed9b-965f-4967-a025-be1366dbbd2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempting to load dataset lmassaron/Sherlock_QA, split train...\n",
            "Dataset loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Load the Sherlock QA dataset\n",
        "data = get_data(repo_id=\"lmassaron/Sherlock_QA\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCYUpfnVR6ij",
        "outputId": "78815866-2eb0-481d-b059-fa7ba52b524a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['messages'],\n",
              "    num_rows: 50994\n",
              "})"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWJC_gamSZEG"
      },
      "outputs": [],
      "source": [
        "# Deterministically sample k rows by setting a random_state\n",
        "if DEMO:\n",
        "    k = 1_000\n",
        "else:\n",
        "    k = len(data)\n",
        "eval_proportion = 0.1\n",
        "eval_size = int(k * eval_proportion)\n",
        "train_size = k - eval_size\n",
        "\n",
        "# Shuffle the dataset with a fixed seed for reproducibility\n",
        "shuffled_data = data.shuffle(seed=params.seed)\n",
        "\n",
        "# Select the first k elements to create your sample\n",
        "sampled_data = shuffled_data.select(range(k))\n",
        "\n",
        "# Split the sampled data into training and test sets\n",
        "train_data = sampled_data.select(range(train_size))\n",
        "eval_data = sampled_data.select(range(train_size, k))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UCMLF4EIQcb",
        "outputId": "4573523f-0d90-45f3-93a1-94dd80fb119e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train examples: 45895\n",
            "eval examples: 5099\n"
          ]
        }
      ],
      "source": [
        "print(f\"train examples: {len(train_data)}\")\n",
        "print(f\"eval examples: {len(eval_data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code block performs a **two-step cleaning process** on your training and evaluation datasets to improve their quality before fine-tuning.\n",
        "\n",
        "1.  **Remove the System Prompt (`.map()`):**\n",
        "    The first step, using `remove_system_prompt`, goes through every single conversation and **deletes the initial system prompt** (e.g., \"You are a helpful assistant.\"). This is often done to force the model to learn the desired behavior purely from the user-assistant examples, rather than relying on a repetitive instruction.\n",
        "\n",
        "2.  **Filter Out Useless Examples (`.filter()`):**\n",
        "    The second step, using `is_example_useful`, inspects every conversation to see if it contains generic, unhelpful answers like \"not specified\" or \"not mentioned\". If it finds any of these phrases, it **removes the entire conversation** from the dataset. This ensures the model is only trained on high-quality examples where a meaningful answer was provided."
      ],
      "metadata": {
        "id": "NJPlIlRtRjkG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNIGX80yY6ng"
      },
      "outputs": [],
      "source": [
        "def remove_system_prompt(example):\n",
        "    if example['messages'][0]['role'] == 'system':\n",
        "        # Return all messages except the first one\n",
        "        return {\"messages\": example['messages'][1:]}\n",
        "    return example\n",
        "\n",
        "def is_example_useful(example):\n",
        "    \"\"\"\n",
        "    Checks if an example is useful. An example is considered not useful if any\n",
        "    of its messages contain one of the unwanted phrases.\n",
        "    \"\"\"\n",
        "    unwanted_phrases = [\n",
        "        \"not specified\",\n",
        "        \"not mentioned\",\n",
        "        \"unknown\",\n",
        "        \"no information provided\",\n",
        "    ]\n",
        "\n",
        "    # Iterate through each message in the conversation\n",
        "    for message in example[\"messages\"]:\n",
        "        # Ensure content is a string before checking\n",
        "        content = message.get(\"content\") or \"\"\n",
        "\n",
        "        # Check if any unwanted phrase is in the message content\n",
        "        if any(phrase in content.lower() for phrase in unwanted_phrases):\n",
        "            return False  # Found an unwanted phrase, mark example for removal\n",
        "\n",
        "    return True  # No unwanted phrases found, keep the example\n",
        "\n",
        "train_data = train_data.map(remove_system_prompt)\n",
        "eval_data = eval_data.map(remove_system_prompt)\n",
        "\n",
        "train_data = train_data.filter(is_example_useful)\n",
        "eval_data = eval_data.filter(is_example_useful)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50OmYdS1IQcc",
        "outputId": "a495c0e5-6aeb-401d-85e4-a161a7fa31b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train examples: 43543\n",
            "eval examples: 4819\n"
          ]
        }
      ],
      "source": [
        "print(f\"train examples: {len(train_data)}\")\n",
        "print(f\"eval examples: {len(eval_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuZoKEAGS0k9"
      },
      "outputs": [],
      "source": [
        "attn_implementation = \"flash_attention_2\" if is_flash_attn_available else \"eager\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    params.MODEL_NAME,\n",
        "    torch_dtype=dtype,\n",
        "    device_map=device,\n",
        "    attn_implementation=attn_implementation\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(params.MODEL_NAME, max_seq_length=params.max_seq_length)\n",
        "\n",
        "# Explicitly enable use_cache for faster inference\n",
        "model.config.use_cache = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9WnzmOZVRjN",
        "outputId": "5427fd64-0e88-4a88-e2e2-215201b7d193"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: google/gemma-3-1b-it\n",
            "Device: cuda:0\n",
            "DType: torch.bfloat16\n",
            "Attention Implementation: flash_attention_2\n"
          ]
        }
      ],
      "source": [
        "print(f\"Model: {model.name_or_path}\")\n",
        "print(f\"Device: {model.device}\")\n",
        "print(f\"DType: {model.dtype}\")\n",
        "print(f\"Attention Implementation: {attn_implementation}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. `peft_config = LoraConfig(...)` - The LoRA Configuration\n",
        "\n",
        "This block sets up the rules for **LoRA (Low-Rank Adaptation)**, which is a highly efficient fine-tuning technique. Instead of training the entire multi-billion parameter model, LoRA freezes the original model and only trains a tiny set of new, small matrices that are \"injected\" into the model's architecture.\n",
        "\n",
        "**Key Parameters:**\n",
        "\n",
        "*   **`r=32` (Rank):** This is the most important parameter. It controls the \"capacity\" or complexity of the small matrices you're training. A higher `r` means more trainable parameters, which can lead to better performance but also uses more memory. `32` is a solid, common choice.\n",
        "*   **`lora_alpha=32`:** A scaling factor that controls the \"strength\" of the LoRA adaptations. A common and effective practice is to set `lora_alpha` equal to `r`.\n",
        "*   **`lora_dropout=0`:** A regularization technique to prevent overfitting. `0` means it's turned off, which is common for LoRA since you are already training very few parameters.\n",
        "*   **`bias=\"none\"`:** Specifies that you will only train the main weight matrices and not the small bias parameters, which is a standard practice for LoRA efficiency.\n",
        "*   **`task_type=\"CAUSAL_LM\"`:** This is crucial. It tells the library that you are fine-tuning a model for next-token prediction (a generative, auto-regressive model like GPT or Llama).\n",
        "*   **`target_modules=[...]`:** This is a list of **which layers inside the model you want to adapt**. The layers listed (`q_proj`, `k_proj`, `v_proj`, etc.) are the most critical components of the Transformer's attention mechanism. By targeting these, you get the most impact from your fine-tuning.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. `training_arguments = SFTConfig(...)` - The Training Rulebook\n",
        "\n",
        "This block defines the complete set of rules and hyperparameters for the entire supervised fine-tuning process. It's the \"master plan\" for the trainer.\n",
        "\n",
        "**Key Parameters (Grouped by Function):**\n",
        "\n",
        "*   **Core Training Loop:**\n",
        "    *   `output_dir=\"logs\"`: Where to save model checkpoints and training logs.\n",
        "    *   `num_train_epochs=1`: The number of times to go through the entire training dataset. `1` is often sufficient for fine-tuning.\n",
        "    *   `seed=params.seed`: Sets a random seed to ensure your results are reproducible.\n",
        "\n",
        "*   **Memory and Batching:**\n",
        "    *   `per_device_train_batch_size=1`: The number of examples to process in a single step. `1` is very small, used to conserve memory.\n",
        "    *   `gradient_accumulation_steps=8`: This is a trick to simulate a larger batch size. The trainer will process 8 small batches of size 1 and *accumulate* their gradients before making a single update to the model. This achieves the stability of a larger batch size (`1 * 8 = 8`) without the high memory cost.\n",
        "\n",
        "*   **Optimizer and Learning Rate:**\n",
        "    *   `optim=\"adamw_torch_fused\"`: Specifies the optimization algorithm. `\"adamw_torch_fused\"` is a highly efficient and fast version of the standard AdamW optimizer.\n",
        "    *   `learning_rate=2e-4`: The step size the optimizer takes. This is one of the most important hyperparameters.\n",
        "    *   `lr_scheduler_type=\"cosine\"`: A popular strategy where the learning rate starts high and then gradually decreases in a cosine curve, which helps the model settle into a good minimum.\n",
        "    *   `warmup_ratio=0.1`: For the first 10% of training, the learning rate will gradually ramp *up* before starting its decay. This helps stabilize the model at the beginning.\n",
        "\n",
        "*   **Hardware and Precision:**\n",
        "    *   `fp16` and `bf16`: These control the numerical precision. The code cleverly checks if your GPU supports `bf16` (the better option) and uses it, otherwise falling back to `fp16`. Using 16-bit precision dramatically reduces memory usage and speeds up training.\n",
        "\n",
        "*   **Logging and Evaluation:**\n",
        "    *   `logging_steps` and `eval_steps`: How often (in steps) to log training metrics and run an evaluation on the `eval_data`.\n",
        "    *   `eval_strategy='steps'`: Specifies that evaluation should happen at regular step intervals.\n",
        "    *   `report_to=\"tensorboard\"`: Sends the logs to TensorBoard for visualization.\n",
        "\n",
        "*   **Dataset Handling:**\n",
        "    *   `dataset_text_field=\"messages\"`: Critically tells the trainer which column in your dataset contains the conversational data.\n",
        "    *   `max_length`: Sets the maximum sequence length for the model, truncating longer examples.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. `trainer = SFTTrainer(...)` - The Trainer Initialization\n",
        "\n",
        "This is the final step where you bring everything together. You create the `SFTTrainer` object, which is the engine that will actually execute the training process based on all the configurations you've just defined.\n",
        "\n",
        "**It takes in:**\n",
        "*   `model=model`: The actual language model you want to fine-tune.\n",
        "*   `train_dataset=train_data`: Your training data.\n",
        "*   `eval_dataset=eval_data`: Your evaluation data for checking performance during training.\n",
        "*   `peft_config=peft_config`: The LoRA rules, which tells the trainer to use this efficient fine-tuning method.\n",
        "*   `processing_class=tokenizer`: The tokenizer needed to process the text data.\n",
        "*   `args=training_arguments`: The complete rulebook for the training process."
      ],
      "metadata": {
        "id": "m6bieCvQSBYA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX14fDV5Vo2c"
      },
      "outputs": [],
      "source": [
        "# LoRA configuration\n",
        "peft_config = LoraConfig(\n",
        "    r=32,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "# SFT (Supervised Fine-tuning) configuration\n",
        "training_arguments = SFTConfig(\n",
        "    output_dir=\"logs\",\n",
        "    seed=params.seed,\n",
        "    num_train_epochs=1,\n",
        "    gradient_checkpointing=False,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=8,\n",
        "    optim=\"adamw_torch_fused\",\n",
        "    save_steps=0,\n",
        "    logging_steps=25 if DEMO else 500,\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.01,\n",
        "    fp16=not(is_bfloat16_supported()),\n",
        "    bf16=is_bfloat16_supported(),\n",
        "    max_grad_norm=0.3,\n",
        "    max_steps=-1,\n",
        "    warmup_ratio=0.1,\n",
        "    group_by_length=False,\n",
        "    eval_strategy='steps',\n",
        "    eval_steps = 25 if DEMO else 500,\n",
        "    eval_accumulation_steps=1,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    dataset_text_field=\"messages\",\n",
        "    packing=False,\n",
        "    max_length=params.max_seq_length,\n",
        "    report_to=\"tensorboard\",\n",
        ")\n",
        "\n",
        "# Initialize the trainer\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=eval_data,\n",
        "    peft_config=peft_config,\n",
        "    processing_class=tokenizer,\n",
        "    args=training_arguments,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "vKbKiqVJXDmH",
        "outputId": "c5ef406a-22b3-46ce-885b-bb5a33986b33"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "It is strongly recommended to train Gemma3 models with the `eager` attention implementation instead of `flash_attention_2`. Use `eager` with `AutoModelForCausalLM.from_pretrained('<path-to-checkpoint>', attn_implementation='eager')`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5737' max='5737' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5737/5737 1:14:43, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Entropy</th>\n",
              "      <th>Num Tokens</th>\n",
              "      <th>Mean Token Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>2.856700</td>\n",
              "      <td>1.945061</td>\n",
              "      <td>1.973937</td>\n",
              "      <td>118400.000000</td>\n",
              "      <td>0.651981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.820200</td>\n",
              "      <td>1.808372</td>\n",
              "      <td>1.809304</td>\n",
              "      <td>237475.000000</td>\n",
              "      <td>0.669743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.703400</td>\n",
              "      <td>1.729094</td>\n",
              "      <td>1.757508</td>\n",
              "      <td>355715.000000</td>\n",
              "      <td>0.679833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.621900</td>\n",
              "      <td>1.677252</td>\n",
              "      <td>1.704830</td>\n",
              "      <td>473546.000000</td>\n",
              "      <td>0.684471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.620200</td>\n",
              "      <td>1.637118</td>\n",
              "      <td>1.595342</td>\n",
              "      <td>591615.000000</td>\n",
              "      <td>0.690248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.571900</td>\n",
              "      <td>1.599872</td>\n",
              "      <td>1.554696</td>\n",
              "      <td>710596.000000</td>\n",
              "      <td>0.694682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>1.530300</td>\n",
              "      <td>1.569115</td>\n",
              "      <td>1.556101</td>\n",
              "      <td>829078.000000</td>\n",
              "      <td>0.699163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.520300</td>\n",
              "      <td>1.537899</td>\n",
              "      <td>1.497680</td>\n",
              "      <td>947322.000000</td>\n",
              "      <td>0.703198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>1.484100</td>\n",
              "      <td>1.520827</td>\n",
              "      <td>1.499347</td>\n",
              "      <td>1065610.000000</td>\n",
              "      <td>0.705701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>1.484600</td>\n",
              "      <td>1.510438</td>\n",
              "      <td>1.500540</td>\n",
              "      <td>1184060.000000</td>\n",
              "      <td>0.706918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>1.471800</td>\n",
              "      <td>1.507154</td>\n",
              "      <td>1.492267</td>\n",
              "      <td>1303335.000000</td>\n",
              "      <td>0.707500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Train model\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned LoRA adapter\n",
        "trainer.model.save_pretrained(\"trained-model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "3WzbnhgSXIVG",
        "outputId": "f0244f61-1b53-46b1-b752-79bdaa2b2b3d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Access the log history\n",
        "log_history = trainer.state.log_history\n",
        "\n",
        "# Extract training / validation loss\n",
        "train_losses = [log[\"loss\"] for log in log_history if \"loss\" in log]\n",
        "epoch_train = [log[\"epoch\"] for log in log_history if \"loss\" in log]\n",
        "eval_losses = [log[\"eval_loss\"] for log in log_history if \"eval_loss\" in log]\n",
        "epoch_eval = [log[\"epoch\"] for log in log_history if \"eval_loss\" in log]\n",
        "\n",
        "# Plot the training loss\n",
        "plt.plot(epoch_train, train_losses, label=\"Training Loss\")\n",
        "plt.plot(epoch_eval, eval_losses, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training and Validation Loss per Epoch\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRy88PKSowMO",
        "colab": {
          "referenced_widgets": [
            "f5fd166e95b349eab31d84e15d7b8c7f",
            "dd708b57768748359e4d0f66d67428c5",
            "fd4fce147ea84dd998ef50a1398cea65",
            "4b8e46c58a8c4634a5294d5c0087faaa"
          ]
        },
        "outputId": "81175d78-aca2-4e12-81c5-5e982b8802ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LoRA adapters saved to gemma-3-1b-sherlock-expert-lora\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5fd166e95b349eab31d84e15d7b8c7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd708b57768748359e4d0f66d67428c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload: |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd4fce147ea84dd998ef50a1398cea65",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b8e46c58a8c4634a5294d5c0087faaa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload: |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and tokenizer pushed to lmassaron/gemma-3-1b-sherlock-expert-lora\n"
          ]
        }
      ],
      "source": [
        "if not DEMO:\n",
        "  lora_output_dir = f\"{params.OUTPUT_MODEL}-lora\"\n",
        "  trainer.model.save_pretrained(lora_output_dir)\n",
        "  print(f\"LoRA adapters saved to {lora_output_dir}\")\n",
        "  # Also save the tokenizer with the LoRA adapters for convenience\n",
        "  tokenizer.save_pretrained(lora_output_dir)\n",
        "\n",
        "  # Define the name for your repository on the Hub\n",
        "  repo_name = \"lmassaron/\" + lora_output_dir\n",
        "\n",
        "  # Push the model to the Hub\n",
        "  model.push_to_hub(repo_name)\n",
        "\n",
        "  # Push the tokenizer to the Hub\n",
        "  tokenizer.push_to_hub(repo_name)\n",
        "\n",
        "  print(f\"Model and tokenizer pushed to {repo_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsRE6Vxdn-1K",
        "colab": {
          "referenced_widgets": [
            "bc88423536bb4faea28ecb6ed00a70e6",
            "ef4992557c2848748402865610e2b45a",
            "face0331f65c4ac89979fd909622035e",
            "4444f037633a4d74b4f33fd4cb2b652c"
          ]
        },
        "outputId": "d00b7c52-a2f6-4c4d-90a2-8d056326deef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Merging the final model\n",
            "Saving the final model to gemma-3-1b-sherlock-expert\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc88423536bb4faea28ecb6ed00a70e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef4992557c2848748402865610e2b45a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload: |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "face0331f65c4ac89979fd909622035e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4444f037633a4d74b4f33fd4cb2b652c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload: |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and tokenizer pushed to lmassaron/gemma-3-1b-sherlock-expert\n"
          ]
        }
      ],
      "source": [
        "if not DEMO:\n",
        "  print(\"\\nMerging the final model\")\n",
        "  merged_model = trainer.model.merge_and_unload()\n",
        "\n",
        "  # Save model and tokenizer\n",
        "  output_path = f\"{params.OUTPUT_MODEL}\"\n",
        "  print(f\"Saving the final model to {output_path}\")\n",
        "  merged_model.save_pretrained(output_path)\n",
        "  tokenizer.save_pretrained(output_path)\n",
        "\n",
        "  # Define the name for your repository on the Hub\n",
        "  repo_name = \"lmassaron/\" + output_path\n",
        "\n",
        "  # Push the model to the Hub\n",
        "  model.push_to_hub(repo_name)\n",
        "\n",
        "  # Push the tokenizer to the Hub\n",
        "  tokenizer.push_to_hub(repo_name)\n",
        "\n",
        "  print(f\"Model and tokenizer pushed to {repo_name}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv (3.12.9)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}