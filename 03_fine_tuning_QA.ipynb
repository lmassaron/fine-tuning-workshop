{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmassaron/fine-tuning-workshop/blob/main/sherlock_knowledge_sft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DdB5YJlNXXq",
        "outputId": "b6d4a199-dd09-4839-91fd-0dc2fc88add9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Sep 24 18:43:25 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.163.01             Driver Version: 550.163.01     CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 3090        Off |   00000000:01:00.0  On |                  N/A |\n",
            "| 30%   35C    P8             29W /  350W |     431MiB /  24576MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A      2036      G   /usr/lib/xorg/Xorg                             92MiB |\n",
            "|    0   N/A  N/A      2184      G   /usr/bin/gnome-shell                           70MiB |\n",
            "|    0   N/A  N/A     22148      C   .../code/sft-workshop/.venv/bin/python        254MiB |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check the GPU information\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "V-Gxk-fyRIzO"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries for model training and evaluation\n",
        "#%%capture\n",
        "#!pip install -U transformers trl peft accelerate bitsandbytes\n",
        "#!pip install tenacity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmVggCLHRIwm",
        "outputId": "a13e6652-c51c-436b-981e-ef310fc0902d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using PyTorch version: 2.8.0+cu128\n",
            "Using TRL version: 0.22.2\n",
            "Using peft version: 0.17.1\n",
            "Using bitsandbytes version: 0.47.0\n"
          ]
        }
      ],
      "source": [
        "# Import and print the versions of the installed libraries\n",
        "import torch\n",
        "import trl\n",
        "import peft\n",
        "import bitsandbytes\n",
        "\n",
        "print(f\"Using PyTorch version: {torch.__version__}\")\n",
        "print(f\"Using TRL version: {trl.__version__}\")\n",
        "print(f\"Using peft version: {peft.__version__}\")\n",
        "print(f\"Using bitsandbytes version: {bitsandbytes.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4XGjIbALROk6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 09-24 18:43:31 [__init__.py:216] Automatically detected platform cuda.\n"
          ]
        }
      ],
      "source": [
        "# Import various libraries needed for data handling, model loading, and training\n",
        "import os\n",
        "import gc\n",
        "import warnings\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import subprocess\n",
        "import sys\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import Dataset, load_dataset\n",
        "from huggingface_hub import login\n",
        "from peft import LoraConfig\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers import set_seed\n",
        "from trl import GRPOConfig, GRPOTrainer, SFTConfig, SFTTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_qqSm9JPqM5C"
      },
      "outputs": [],
      "source": [
        "DEMO = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MqjLdOThRIte"
      },
      "outputs": [],
      "source": [
        "# Define configuration parameters for the model and data\n",
        "class Config:\n",
        "    \"\"\"Configuration parameters\"\"\"\n",
        "\n",
        "    SIZE = \"3-1b\"\n",
        "    MODEL_NAME = f\"google/gemma-{SIZE}-it\"\n",
        "    OUTPUT_MODEL = f\"gemma-{SIZE}-sherlock-expert\"\n",
        "\n",
        "    max_seq_length = 2048\n",
        "    seed = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ar0-cOqPRIlN"
      },
      "outputs": [],
      "source": [
        "# Initialization script to set up the environment and Hugging Face login\n",
        "def init():\n",
        "    \"\"\"Initialization script\"\"\"\n",
        "    os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"0\"\n",
        "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
        "\n",
        "    # It is recommended to set the HF_TOKEN as an environment variable\n",
        "    token = os.environ.get(\"HF_TOKEN\")\n",
        "    if token:\n",
        "        login(token=token)\n",
        "    else:\n",
        "      try:\n",
        "        from google.colab import userdata\n",
        "        # Retrieve your Hugging Face token from Colab's secrets manager\n",
        "        # The name 'HF_TOKEN' should match the name you used in the secrets tab\n",
        "        hf_token = userdata.get('HF_TOKEN')\n",
        "\n",
        "        # Check if the token was successfully retrieved\n",
        "        if hf_token:\n",
        "            # Log in to Hugging Face using the retrieved token\n",
        "            # The `add_to_git_credential=True` argument is optional and useful if you plan to push models to the Hub\n",
        "            login(token=hf_token, add_to_git_credential=True)\n",
        "            print(\"Hugging Face login successful using Google Colab secrets!\")\n",
        "        else:\n",
        "            print(\"Error: HF_TOKEN not found in Google Colab secrets or is empty.\")\n",
        "            print(\"Please ensure you have created a secret named 'HF_TOKEN' in the 'Secrets' tab (ðŸ”‘) on the left sidebar.\")\n",
        "      except:\n",
        "        print(\"HF_TOKEN not set. You might need to log in manually.\")\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def is_bfloat16_supported():\n",
        "    \"\"\"Checks if the current device supports bfloat16.\"\"\"\n",
        "    return torch.cuda.is_available() and torch.cuda.get_device_capability(0)[0] >= 8\n",
        "\n",
        "\n",
        "def info_device():\n",
        "    \"\"\"Get device for PyTorch\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "    return device\n",
        "\n",
        "def cleanup(objects=None):\n",
        "    \"\"\"Cleans the memory\"\"\"\n",
        "    if objects is not None:\n",
        "        for obj in objects:\n",
        "            del obj\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "def set_deterministic(seed):\n",
        "  \"\"\"Sets all seeds and CUDA settings for deterministic results.\"\"\"\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU. [2, 3]\n",
        "  set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wJQUgDsNTeqr"
      },
      "outputs": [],
      "source": [
        "def install_flash_attn_conditionally():\n",
        "    \"\"\"\n",
        "    Checks the GPU's compute capability and installs the appropriate version of flash-attn.\n",
        "    \"\"\"\n",
        "    if not torch.cuda.is_available():\n",
        "        print(\"No CUDA-enabled GPU found. Skipping flash-attn installation.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Get the compute capability of the first available GPU\n",
        "        major, minor = torch.cuda.get_device_capability(0)\n",
        "        compute_capability = float(f\"{major}.{minor}\")\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        print(f\"Found GPU: {gpu_name} with Compute Capability: {compute_capability}\")\n",
        "\n",
        "        # Check for Ampere, Ada, Hopper, or newer architectures (for FlashAttention 2)\n",
        "        if compute_capability >= 8.0:\n",
        "            # Ampere, Ada, and Hopper architectures support bfloat16 and are ideal for FlashAttention 2\n",
        "            is_bf16_supported = torch.cuda.is_bf16_supported()\n",
        "            if is_bf16_supported:\n",
        "                print(\"GPU supports BF16 and is compatible with FlashAttention 2.\")\n",
        "                print(\"Proceeding with installation of the latest 'flash-attn'...\")\n",
        "                # Install the latest version of flash-attn\n",
        "                install_package(\"flash-attn\", \"-q\", \"--no-build-isolation\") # Pass arguments correctly\n",
        "                return True\n",
        "            else:\n",
        "                 print(\"GPU architecture is compatible, but BF16 is not supported. Skipping installation.\")\n",
        "                 return False\n",
        "        # Check for Turing architecture (for original FlashAttention)\n",
        "        elif compute_capability == 7.5:\n",
        "            print(\"Turing architecture GPU detected. Compatible with original FlashAttention (v1.x).\")\n",
        "            print(\"Proceeding with installation of 'flash-attn==1.0.9'...\")\n",
        "            # Install a specific version of flash-attn compatible with Turing\n",
        "            install_package(\"flash-attn==1.0.9\", \"-q\", \"--no-build-isolation\") # Pass arguments correctly\n",
        "            return True\n",
        "\n",
        "        else:\n",
        "            print(f\"GPU with compute capability {compute_capability} is not supported by flash-attn. Skipping installation.\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during GPU check or installation: {e}\")\n",
        "        return False\n",
        "\n",
        "def install_package(package_name, *pip_args):\n",
        "    \"\"\"\n",
        "    A helper function to install a pip package using subprocess.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        command = [sys.executable, \"-m\", \"pip\", \"install\", package_name]\n",
        "        command.extend(pip_args) # Extend with individual arguments\n",
        "        subprocess.check_call(command)\n",
        "        print(f\"Successfully installed {package_name}.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error installing {package_name}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3_Z-8ANQchp",
        "outputId": "d00ab44d-744d-4195-e9b2-a50d5808189d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Using dtype: torch.bfloat16\n",
            "Found GPU: NVIDIA GeForce RTX 3090 with Compute Capability: 8.6\n",
            "GPU supports BF16 and is compatible with FlashAttention 2.\n",
            "Proceeding with installation of the latest 'flash-attn'...\n",
            "Successfully installed flash-attn.\n"
          ]
        }
      ],
      "source": [
        "# Initialize the environment, get parameters, device, and data type\n",
        "init()\n",
        "params = Config()\n",
        "device = info_device()\n",
        "dtype = torch.bfloat16 if is_bfloat16_supported() else torch.float16\n",
        "print(f\"Using dtype: {dtype}\")\n",
        "is_flash_attn_available = install_flash_attn_conditionally()\n",
        "set_deterministic(params.seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GsqZ-Jr3R12y"
      },
      "outputs": [],
      "source": [
        "from tenacity import retry, stop_after_attempt, wait_fixed\n",
        "\n",
        "# Function to load dataset from Hugging Face Hub with retries\n",
        "@retry(stop=stop_after_attempt(5), wait=wait_fixed(10)) # Retry up to 5 times with 10 seconds delay\n",
        "def get_data(repo_id, mapping_func=None, split=\"train\"):\n",
        "    \"\"\"Upload HF dataset with retries\"\"\"\n",
        "    print(f\"Attempting to load dataset {repo_id}, split {split}...\")\n",
        "    data = load_dataset(repo_id, cache_dir=\"/tmp\")[split]\n",
        "    if mapping_func:\n",
        "      data = data.map(mapping_func)\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "h2oTLcc9R2iY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempting to load dataset lmassaron/Sherlock_QA, split train...\n",
            "Dataset loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Load the Sherlock QA dataset\n",
        "data = get_data(repo_id=\"lmassaron/Sherlock_QA\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCYUpfnVR6ij",
        "outputId": "78815866-2eb0-481d-b059-fa7ba52b524a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['messages'],\n",
              "    num_rows: 44294\n",
              "})"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kWJC_gamSZEG"
      },
      "outputs": [],
      "source": [
        "# Deterministically sample k rows by setting a random_state\n",
        "if DEMO:\n",
        "    k = 1_000\n",
        "else:\n",
        "    k = len(data)\n",
        "eval_proportion = 0.1\n",
        "eval_size = int(k * eval_proportion)\n",
        "train_size = k - eval_size\n",
        "\n",
        "# Shuffle the dataset with a fixed seed for reproducibility\n",
        "shuffled_data = data.shuffle(seed=params.seed)\n",
        "\n",
        "# Select the first k elements to create your sample\n",
        "sampled_data = shuffled_data.select(range(k))\n",
        "\n",
        "# Split the sampled data into training and test sets\n",
        "train_data = sampled_data.select(range(train_size))\n",
        "eval_data = sampled_data.select(range(train_size, k))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MNIGX80yY6ng"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6bcc0e1f235d4e59805d8c9fd6010355",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/39865 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9e6943a9a8f45f1977b99dc3ade714c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/4429 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47784d114fe44dddbde3625a610bbab8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/39865 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "291571e8b9c741df9049ef6cbb027fa8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/4429 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def remove_system_prompt(example):\n",
        "    if example['messages'][0]['role'] == 'system':\n",
        "        # Return all messages except the first one\n",
        "        return {\"messages\": example['messages'][1:]}\n",
        "    return example\n",
        "\n",
        "\n",
        "def remove_unuseful_messages(example):\n",
        "    \"\"\"\n",
        "    Removes messages from an example if their content contains any of the\n",
        "    unwanted phrases.\n",
        "    \"\"\"\n",
        "    unwanted_phrases = [\n",
        "        \"not specified\",\n",
        "        \"not mentioned\",\n",
        "        \"unknown\",\n",
        "        \"no information provided\",\n",
        "    ]\n",
        "\n",
        "    # Create a new list of messages, keeping only the ones that are useful\n",
        "    useful_messages = []\n",
        "    for message in example[\"messages\"]:\n",
        "        # Check if any of the unwanted phrases are in the message content (case-insensitive)\n",
        "        if not any(phrase in message[\"content\"].lower() for phrase in unwanted_phrases):\n",
        "            useful_messages.append(message)\n",
        "\n",
        "    return {\"messages\": useful_messages}\n",
        "\n",
        "\n",
        "train_data = train_data.map(remove_system_prompt)\n",
        "eval_data = eval_data.map(remove_system_prompt)\n",
        "\n",
        "train_data = train_data.map(remove_unuseful_messages)\n",
        "eval_data = eval_data.map(remove_unuseful_messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempting to load dataset lmassaron/Sherlock_QA_test, split train...\n",
            "Dataset loaded successfully!\n",
            "The answer to the question 0 (Who created the character of Sherlock Holmes?) appears 180 times in the training data\n",
            "The answer to the question 1 (What is the name of Sherlock Holmes's enemy?) appears 64 times in the training data\n",
            "The answer to the question 2 (Where does Sherlock Holmes live?) appears 0 times in the training data\n",
            "The answer to the question 3 (Who is Sherlock Holmes's best friend?) appears 19 times in the training data\n",
            "The answer to the question 4 (What is the name of Sherlock's older brother?) appears 35 times in the training data\n",
            "The answer to the question 5 (Who is the landlady of 221b Baker Street?) appears 25 times in the training data\n",
            "The answer to the question 6 (What musical instrument does Sherlock Holmes like ) appears 4 times in the training data\n",
            "The answer to the question 7 (In which Sherlock Holmes short story do we meet Ir) appears 7 times in the training data\n",
            "The answer to the question 8 (Which actor plays Sherlock Holmes in the TV series) appears 8 times in the training data\n",
            "The answer to the question 9 (Who did Dr. Watson marry?) appears 0 times in the training data\n",
            "The answer to the question 10 (What are the street boys called who run errands fo) appears 27 times in the training data\n",
            "The answer to the question 11 (Who stars as Sherlock Holmes in the 2009 film Sher) appears 5 times in the training data\n",
            "The answer to the question 12 (Who stars as Watson in the 2009 film Sherlock Holm) appears 1 times in the training data\n",
            "The answer to the question 13 (What was the first Sherlock Holmes story titled?) appears 21 times in the training data\n",
            "The answer to the question 14 (Which 2020 film features the teenage sister of She) appears 10 times in the training data\n",
            "The answer to the question 15 (Where did Sherlock and Watson first meet?) appears 0 times in the training data\n",
            "The answer to the question 16 (When Sherlock Holmes retired, what hobby did he ta) appears 0 times in the training data\n",
            "The answer to the question 17 (Where does Sherlock Holmes keep his tobacco?) appears 0 times in the training data\n",
            "The answer to the question 18 (What is the client's name in the short story \"The ) appears 1 times in the training data\n",
            "The answer to the question 19 (What was the title of the short story published in) appears 32 times in the training data\n",
            "The answer to the question 20 (What was the first book released after everyone be) appears 97 times in the training data\n",
            "The answer to the question 21 (What object is the Blue Carbuncle?) appears 0 times in the training data\n",
            "The answer to the question 22 (What is Sherlock Holmes's most famous line?) appears 0 times in the training data\n",
            "The answer to the question 23 (On what British TV channel is the series Sherlock ) appears 3 times in the training data\n",
            "The answer to the question 24 (In The Hound Of The Baskervilles, what village doe) appears 3 times in the training data\n"
          ]
        }
      ],
      "source": [
        "test_data = get_data(repo_id=\"lmassaron/Sherlock_QA_test\")\n",
        "\n",
        "for k, item in enumerate(test_data):\n",
        "    answer = item[\"Answer\"].lower()\n",
        "    counter = 0\n",
        "    for messages in train_data:\n",
        "        for content in messages[\"messages\"]:\n",
        "            if content[\"role\"] == \"assistant\":\n",
        "                if answer in content[\"content\"].lower():\n",
        "                    counter += 1\n",
        "    print(\n",
        "        f\"The answer to the question {k} ({item[\"Question\"][:50]}) appears {counter} times in the training data\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kuZoKEAGS0k9"
      },
      "outputs": [],
      "source": [
        "attn_implementation = \"flash_attention_2\" if is_flash_attn_available else \"eager\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    params.MODEL_NAME,\n",
        "    torch_dtype=dtype,\n",
        "    device_map=device,\n",
        "    attn_implementation=attn_implementation\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(params.MODEL_NAME, max_seq_length=params.max_seq_length)\n",
        "\n",
        "# Explicitly enable use_cache for faster inference\n",
        "model.config.use_cache = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9WnzmOZVRjN",
        "outputId": "5427fd64-0e88-4a88-e2e2-215201b7d193"
      },
      "outputs": [],
      "source": [
        "print(f\"Model: {model.name_or_path}\")\n",
        "print(f\"Device: {model.device}\")\n",
        "print(f\"DType: {model.dtype}\")\n",
        "print(f\"Attention Implementation: {attn_implementation}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "QX14fDV5Vo2c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8911ee796c6b4ec0b24ff855ce5d9ac1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing train dataset:   0%|          | 0/39865 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ffe9588e13e455980cf2a2ce062dc1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Truncating train dataset:   0%|          | 0/39865 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9007cfc861fe44b6a6de0ae8a1e65ff4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing eval dataset:   0%|          | 0/4429 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c692ced6bcab4c51b2734ba418d364be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Truncating eval dataset:   0%|          | 0/4429 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# LoRA configuration\n",
        "peft_config = LoraConfig(\n",
        "    r=32,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "# SFT (Supervised Fine-tuning) configuration\n",
        "training_arguments = SFTConfig(\n",
        "    output_dir=\"logs\",\n",
        "    seed=params.seed,\n",
        "    num_train_epochs=3,\n",
        "    gradient_checkpointing=False,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=8,\n",
        "    optim=\"adamw_torch_fused\",\n",
        "    save_steps=0,\n",
        "    logging_steps=25 if DEMO else 500,\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.01,\n",
        "    fp16=not(is_bfloat16_supported()),\n",
        "    bf16=is_bfloat16_supported(),\n",
        "    max_grad_norm=0.3,\n",
        "    max_steps=-1,\n",
        "    warmup_ratio=0.1,\n",
        "    group_by_length=False,\n",
        "    eval_strategy='steps',\n",
        "    eval_steps = 25 if DEMO else 500,\n",
        "    eval_accumulation_steps=1,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    dataset_text_field=\"messages\",\n",
        "    packing=False,\n",
        "    max_length=params.max_seq_length,\n",
        "    report_to=\"tensorboard\",\n",
        ")\n",
        "\n",
        "# Initialize the trainer\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=eval_data,\n",
        "    peft_config=peft_config,\n",
        "    processing_class=tokenizer,\n",
        "    args=training_arguments,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "vKbKiqVJXDmH",
        "outputId": "c5ef406a-22b3-46ce-885b-bb5a33986b33"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "It is strongly recommended to train Gemma3 models with the `eager` attention implementation instead of `flash_attention_2`. Use `eager` with `AutoModelForCausalLM.from_pretrained('<path-to-checkpoint>', attn_implementation='eager')`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='14952' max='14952' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [14952/14952 2:55:16, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Entropy</th>\n",
              "      <th>Num Tokens</th>\n",
              "      <th>Mean Token Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.334000</td>\n",
              "      <td>1.997690</td>\n",
              "      <td>1.992775</td>\n",
              "      <td>116774.000000</td>\n",
              "      <td>0.647461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.853500</td>\n",
              "      <td>1.847683</td>\n",
              "      <td>1.909873</td>\n",
              "      <td>233727.000000</td>\n",
              "      <td>0.663309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.745400</td>\n",
              "      <td>1.777246</td>\n",
              "      <td>1.682419</td>\n",
              "      <td>351217.000000</td>\n",
              "      <td>0.674761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.714700</td>\n",
              "      <td>1.726389</td>\n",
              "      <td>1.687213</td>\n",
              "      <td>467663.000000</td>\n",
              "      <td>0.678707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.648200</td>\n",
              "      <td>1.676664</td>\n",
              "      <td>1.600140</td>\n",
              "      <td>584195.000000</td>\n",
              "      <td>0.686604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.613300</td>\n",
              "      <td>1.645983</td>\n",
              "      <td>1.676838</td>\n",
              "      <td>701240.000000</td>\n",
              "      <td>0.691611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>1.593100</td>\n",
              "      <td>1.617079</td>\n",
              "      <td>1.647116</td>\n",
              "      <td>818437.000000</td>\n",
              "      <td>0.692701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.555300</td>\n",
              "      <td>1.591569</td>\n",
              "      <td>1.510214</td>\n",
              "      <td>935118.000000</td>\n",
              "      <td>0.697029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>1.534800</td>\n",
              "      <td>1.571333</td>\n",
              "      <td>1.477403</td>\n",
              "      <td>1051176.000000</td>\n",
              "      <td>0.699340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>1.516100</td>\n",
              "      <td>1.565995</td>\n",
              "      <td>1.334558</td>\n",
              "      <td>1168164.000000</td>\n",
              "      <td>0.700900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>1.297300</td>\n",
              "      <td>1.561082</td>\n",
              "      <td>1.270942</td>\n",
              "      <td>1284981.000000</td>\n",
              "      <td>0.703806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>1.304200</td>\n",
              "      <td>1.530227</td>\n",
              "      <td>1.413187</td>\n",
              "      <td>1401539.000000</td>\n",
              "      <td>0.706123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>1.311900</td>\n",
              "      <td>1.518522</td>\n",
              "      <td>1.340050</td>\n",
              "      <td>1518765.000000</td>\n",
              "      <td>0.708209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>1.296700</td>\n",
              "      <td>1.506291</td>\n",
              "      <td>1.325918</td>\n",
              "      <td>1635711.000000</td>\n",
              "      <td>0.710541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>1.280200</td>\n",
              "      <td>1.493976</td>\n",
              "      <td>1.292779</td>\n",
              "      <td>1752806.000000</td>\n",
              "      <td>0.712371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>1.267800</td>\n",
              "      <td>1.476195</td>\n",
              "      <td>1.310782</td>\n",
              "      <td>1869381.000000</td>\n",
              "      <td>0.714026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>1.264100</td>\n",
              "      <td>1.462974</td>\n",
              "      <td>1.283906</td>\n",
              "      <td>1986358.000000</td>\n",
              "      <td>0.716853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>1.253100</td>\n",
              "      <td>1.446636</td>\n",
              "      <td>1.266328</td>\n",
              "      <td>2103638.000000</td>\n",
              "      <td>0.718971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>1.234700</td>\n",
              "      <td>1.435656</td>\n",
              "      <td>1.276228</td>\n",
              "      <td>2219518.000000</td>\n",
              "      <td>0.719755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>1.204800</td>\n",
              "      <td>1.461386</td>\n",
              "      <td>1.101697</td>\n",
              "      <td>2336293.000000</td>\n",
              "      <td>0.720587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.963600</td>\n",
              "      <td>1.498983</td>\n",
              "      <td>1.049240</td>\n",
              "      <td>2453210.000000</td>\n",
              "      <td>0.721006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.959300</td>\n",
              "      <td>1.501366</td>\n",
              "      <td>1.038744</td>\n",
              "      <td>2569957.000000</td>\n",
              "      <td>0.721621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.951900</td>\n",
              "      <td>1.497046</td>\n",
              "      <td>1.042115</td>\n",
              "      <td>2687282.000000</td>\n",
              "      <td>0.721991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.944200</td>\n",
              "      <td>1.493673</td>\n",
              "      <td>1.029557</td>\n",
              "      <td>2803966.000000</td>\n",
              "      <td>0.723100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.937000</td>\n",
              "      <td>1.492220</td>\n",
              "      <td>1.027995</td>\n",
              "      <td>2920332.000000</td>\n",
              "      <td>0.723487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.930900</td>\n",
              "      <td>1.494125</td>\n",
              "      <td>1.022650</td>\n",
              "      <td>3037064.000000</td>\n",
              "      <td>0.724040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.949400</td>\n",
              "      <td>1.486623</td>\n",
              "      <td>1.033673</td>\n",
              "      <td>3154019.000000</td>\n",
              "      <td>0.724414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.938200</td>\n",
              "      <td>1.489279</td>\n",
              "      <td>1.028796</td>\n",
              "      <td>3271031.000000</td>\n",
              "      <td>0.724908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>0.935300</td>\n",
              "      <td>1.490537</td>\n",
              "      <td>1.021612</td>\n",
              "      <td>3387930.000000</td>\n",
              "      <td>0.724566</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Train model\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned LoRA adapter\n",
        "trainer.model.save_pretrained(\"trained-model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "3WzbnhgSXIVG",
        "outputId": "f0244f61-1b53-46b1-b752-79bdaa2b2b3d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Access the log history\n",
        "log_history = trainer.state.log_history\n",
        "\n",
        "# Extract training / validation loss\n",
        "train_losses = [log[\"loss\"] for log in log_history if \"loss\" in log]\n",
        "epoch_train = [log[\"epoch\"] for log in log_history if \"loss\" in log]\n",
        "eval_losses = [log[\"eval_loss\"] for log in log_history if \"eval_loss\" in log]\n",
        "epoch_eval = [log[\"epoch\"] for log in log_history if \"eval_loss\" in log]\n",
        "\n",
        "# Plot the training loss\n",
        "plt.plot(epoch_train, train_losses, label=\"Training Loss\")\n",
        "plt.plot(epoch_eval, eval_losses, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training and Validation Loss per Epoch\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "HRy88PKSowMO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LoRA adapters saved to gemma-3-1b-sherlock-expert-lora\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a62c32c0c84b459797bb83aaae9eaa75",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02600e4b4c2c4c21a3da27696e077e48",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3de230720854ff989d2d608d1bbafeb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload: |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a721953856464be7ae3945a73820df5e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e13aab558c4425487bafc6ccf593045",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload: |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and tokenizer pushed to lmassaron/gemma-3-1b-sherlock-expert-lora\n"
          ]
        }
      ],
      "source": [
        "if not DEMO:\n",
        "  lora_output_dir = f\"{params.OUTPUT_MODEL}-lora\"\n",
        "  trainer.model.save_pretrained(lora_output_dir)\n",
        "  print(f\"LoRA adapters saved to {lora_output_dir}\")\n",
        "  # Also save the tokenizer with the LoRA adapters for convenience\n",
        "  tokenizer.save_pretrained(lora_output_dir)\n",
        "\n",
        "  # Define the name for your repository on the Hub\n",
        "  repo_name = \"lmassaron/\" + lora_output_dir\n",
        "\n",
        "  # Push the model to the Hub\n",
        "  model.push_to_hub(repo_name)\n",
        "\n",
        "  # Push the tokenizer to the Hub\n",
        "  tokenizer.push_to_hub(repo_name)\n",
        "\n",
        "  print(f\"Model and tokenizer pushed to {repo_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jsRE6Vxdn-1K"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Merging the final model\n",
            "Saving the final model to gemma-3-1b-sherlock-expert\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e136476659e948fa9565e13687a64c97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24ff5c025cbf48a7837dc4336142888d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c64132adf31548b4821e05e048ec05d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload: |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51cd87d8506b47d9ba7118b1e0d996c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bf05e1d54f14f199a9b51257aae88ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload: |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and tokenizer pushed to lmassaron/gemma-3-1b-sherlock-expert\n"
          ]
        }
      ],
      "source": [
        "if not DEMO:\n",
        "  print(\"\\nMerging the final model\")\n",
        "  merged_model = trainer.model.merge_and_unload()\n",
        "\n",
        "  # Save model and tokenizer\n",
        "  output_path = f\"{params.OUTPUT_MODEL}\"\n",
        "  print(f\"Saving the final model to {output_path}\")\n",
        "  merged_model.save_pretrained(output_path)\n",
        "  tokenizer.save_pretrained(output_path)\n",
        "\n",
        "  # Define the name for your repository on the Hub\n",
        "  repo_name = \"lmassaron/\" + output_path\n",
        "\n",
        "  # Push the model to the Hub\n",
        "  model.push_to_hub(repo_name)\n",
        "\n",
        "  # Push the tokenizer to the Hub\n",
        "  tokenizer.push_to_hub(repo_name)\n",
        "\n",
        "  print(f\"Model and tokenizer pushed to {repo_name}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyONABkP/zRuPIHkM/R6+plb",
      "gpuType": "L4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.12.9)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
